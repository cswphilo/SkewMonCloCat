
@article{dosen_cut_2008,
	title = {Cut elimination in categories},
	volume = {6},
	number = {January},
	author = {Dosen, Kosta},
	year = {2008},
	pages = {1--276},
	file = {Attachment:/Users/wanchengsyuan/Zotero/storage/QM96685G/Cut-Elimination-in-Categories.pdf:application/pdf},
}

@book{troelstra_basic_2000,
	title = {Basic {Proof} {Theory}},
	isbn = {978-0-521-77911-1},
	url = {https://www.cambridge.org/core/product/identifier/9781139168717/type/book},
	publisher = {Cambridge University Press},
	author = {Troelstra, A. S. and Schwichtenberg, H.},
	year = {2000},
	doi = {10.1017/CBO9781139168717},
}

@book{leinster_basic_2014,
	title = {Basic category theory},
	isbn = {978-1-107-36006-8},
	abstract = {At the heart of this short introduction to category theory is the idea of a universal property, important throughout mathematics. After an introductory chapter giving the basic definitions, separate chapters explain three ways of expressing universal properties: via adjoint functors, representable functors, and limits. A final chapter ties all three together. The book is suitable for use in courses or for independent study. Assuming relatively little mathematical background, it is ideal for beginning graduate students or advanced undergraduates learning category theory for the first time. For each new categorical concept, a generous supply of examples is provided, taken from different parts of mathematics. At points where the leap in abstraction is particularly great (such as the Yoneda lemma), the reader will find careful and extensive explanations. Copious exercises are included.},
	author = {Leinster, Tom},
	year = {2014},
	doi = {10.1017/CBO9781107360068},
	note = {Publication Title: Basic Category Theory
\_eprint: 1612.09375},
	file = {Attachment:/Users/wanchengsyuan/Zotero/storage/CVI2787S/Basic Category Theory.pdf:application/pdf},
}

@article{altenkirch_categorical_1995,
	title = {Categorical reconstruction of a reduction free normalization proof},
	volume = {953},
	issn = {16113349},
	doi = {10.1007/3-540-60164-3_27},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Altenkirch, Thorsten and Hofmann, Martin and Streicher, Thomas},
	year = {1995},
	note = {ISBN: 3540601643},
	pages = {182--199},
	file = {Attachment:/Users/wanchengsyuan/Zotero/storage/FK3UGAIT/ctcs95.pdf:application/pdf},
}

@article{lawvere_first_2009,
	title = {A {First} {Introduction} {To} {Categories}},
	author = {Lawvere, Willian F. and Schanuel, Stephen H.},
	year = {2009},
	pages = {385},
	file = {Attachment:/Users/wanchengsyuan/Zotero/storage/DI8BBSU6/Conceptual-Mathematics-A-First-Introduction-to-Categories.pdf:application/pdf},
}

@article{girard_proofs_nodate,
	title = {Proofs and {Types} - {Girard}, {Taylor} {Lafont}},
	author = {Girard, Jean-yves},
	file = {Attachment:/Users/wanchengsyuan/Zotero/storage/H7RLEQVG/Proofs-and-Types.pdf:application/pdf},
}

@techreport{howard_formulae-as-types_nodate,
	title = {The formulae-as-types notion of construction},
	abstract = {Dedicated to H. B. Curry on the occasion of his 80th birthday. The following consists of notes which were privately circulated in 1969. Since they have been referred to a few times in the literature, it seems worth while to publish them. They have been rearranged for easier reading, and some inessential corrections have been made. The ultimate goal was to develop a notion of construction suitable for the interpretation of intuitionistic mathematics. The notion of construction developed in the notes is certainly too crude for that, so the use of the word construction is not very appropriate. However, the terminology has been kept in order to preserve the original title and also to preserve the character of the notes. The title has a second defect; namely, a type should be regarded as a abstract object whereas a formula is the name of a type. In Part I the ideas are illustrated for the intuitionistic propositional calculus and in Part II (page 6) they are applied to Heyting arithmetic. I Intuitionistic propositional calculus H. Curry (1958) has observed that there is a close correspondence between axioms of positive implicational propositional logic, on the one hand, and basic combina},
	author = {Howard, W H},
	file = {Attachment:/Users/wanchengsyuan/Zotero/storage/J8HMFTV8/Howard - Unknown - The formulae-as-types notion of construction.pdf:application/pdf},
}

@article{abramsky_introduction_2011,
	title = {Introduction to categories and categorical logic},
	volume = {813},
	issn = {00758450},
	doi = {10.1007/978-3-642-12821-9_1},
	abstract = {The aim of these notes is to provide a succinct, accessible introduction to some of the basic ideas of category theory and categorical logic. The notes are based on a lecture course given at Oxford over the past few years. They contain numerous exercises, and hopefully will prove useful for self-study by those seeking a first introduction to the subject, with fairly minimal prerequisites. The coverage is by no means comprehensive, but should provide a good basis for further study; a guide to further reading is included. The main prerequisite is a basic familiarity with the elements of discrete mathematics: sets, relations and functions. An Appendix contains a summary of what we will need, and it may be useful to review this first. In addition, some prior exposure to abstract algebra-vector spaces and linear maps, or groups and group homomorphisms-would be helpful. © 2010 Springer-Verlag Berlin Heidelberg.},
	journal = {Lecture Notes in Physics},
	author = {Abramsky, S. and Tzevelekos, N.},
	year = {2011},
	note = {ISBN: 9783642128202
\_eprint: 1102.1313},
	pages = {3--94},
	file = {Attachment:/Users/wanchengsyuan/Zotero/storage/HV7Y8JQP/ICCL.pdf:application/pdf},
}

@book{negri_structural_2001,
	title = {Structural {Proof} {Theory}},
	isbn = {978-0-521-79307-0},
	url = {https://www.cambridge.org/core/product/identifier/9780511527340/type/book},
	publisher = {Cambridge University Press},
	author = {Negri, Sara and von Plato, Jan and Ranta, Aarne},
	year = {2001},
	doi = {10.1017/CBO9780511527340},
}

@book{awodey_category_2007,
	title = {Category {Theory}},
	isbn = {978-0-19-171756-7},
	abstract = {This book is a text and reference book on Category Theory, a branch of abstract algebra. The book contains clear definitions of the essential concepts, which are illuminated with numerous accessible examples. It provides full proofs of all the important propositions and theorems, and aims to make the basic ideas, theorems, and methods of Category Theory understandable. Although it assumes few mathematical pre-requisites, the standard of mathematical rigour is not compromised. The material covered includes the standard core of categories; functors; natural transformations; equivalence; limits and colimits; functor categories; representables; Yoneda's lemma; adjoints; and monads. An extra topic of cartesian closed categories and the lambda-calculus is also provided.},
	author = {Awodey, Steve},
	year = {2007},
	doi = {10.1093/acprof:oso/9780198568612.001.0001},
	note = {Publication Title: Category Theory},
	keywords = {Adjoints, Cartesian closed categories, Equivalence, Functor categories, Functors, Limits and colimits, Monads, Natural transformations, Representables, Yoneda's lemma},
}

@article{bell_introduction_1989,
	title = {Introduction to {Higher} {Order} {Categorical} {Logic}.},
	volume = {54},
	issn = {00224812},
	doi = {10.2307/2274784},
	abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-α-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\textbackslash}AA for the interface backbone atoms) increased from 21\% with default Glide SP settings to 58\% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63\% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40\% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
	number = {3},
	journal = {The Journal of Symbolic Logic},
	author = {Bell, J. L. and Lambek, J. and Scott, P. J.},
	year = {1989},
	note = {Publisher: Cambridge University Press (CUP)},
	pages = {1113},
}

@book{jacobs_categorical_1999,
	title = {Categorical logic and type theory},
	isbn = {978-0-444-50170-7},
	abstract = {This book is an attempt to give a systematic presentation of both logic and type theory from a categorical perspective, using the unifying concept of fibred category. Its intended audience consists of logicians, type theorists, category theorists and (theoretical) computer scientists.},
	author = {Jacobs, B},
	year = {1999},
	doi = {10.1016/S0049-237X(98)X8028-6},
	note = {Publication Title: Foundations},
}

@book{crole_categories_1994,
	title = {Categories for {Types}},
	isbn = {978-0-521-45092-8},
	url = {https://www.cambridge.org/core/product/identifier/9781139172707/type/book},
	publisher = {Cambridge University Press},
	author = {Crole, Roy L.},
	year = {1994},
	doi = {10.1017/CBO9781139172707},
}

@article{martin-lof_intuitionistic_nodate,
	title = {Intuitionistic {Type} {Theory}},
	author = {Martin-Löf, Per},
}

@article{smith_category_2016,
	title = {Category theory: a gentle introduction},
	author = {Smith, Peter},
	year = {2016},
}

@article{maclane_categories_1971,
	title = {Categories for the working mathematician},
	author = {MacLane, Saunders},
	year = {1971},
	note = {Publisher: Springer},
}

@article{lawvere_functorial_1963,
	title = {Functorial semantics of algebraic theories},
	volume = {50},
	number = {5},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Lawvere, F William},
	year = {1963},
	note = {Publisher: National Academy of Sciences},
	pages = {869},
}

@article{lawvere_elementary_1964,
	title = {An elementary theory of the category of sets},
	volume = {52},
	number = {6},
	journal = {Proceedings of the National academy of Sciences of the United States of America},
	author = {Lawvere, F William},
	year = {1964},
	note = {Publisher: National Academy of Sciences},
	pages = {1506},
}

@article{lawvere_adjointness_1969,
	title = {Adjointness in foundations},
	volume = {23},
	number = {3-4},
	journal = {Dialectica},
	author = {Lawvere, F William},
	year = {1969},
	note = {Publisher: Wiley Online Library},
	pages = {281--296},
}

@article{godel_uber_1931,
	title = {Über formal unentscheidbare {Sätze} der {Principia} {Mathematica} und verwandter {Systeme} {I}},
	volume = {38},
	number = {1},
	journal = {Monatshefte für mathematik und physik},
	author = {Gödel, Kurt},
	year = {1931},
	note = {Publisher: Springer},
	pages = {173--198},
}

@article{gentzen_untersuchungen_1935,
	title = {Untersuchungen über das logische {Schließen}. {I}},
	volume = {39},
	number = {1},
	journal = {Mathematische zeitschrift},
	author = {Gentzen, Gerhard},
	year = {1935},
	note = {Publisher: Springer},
	pages = {176--210},
}

@article{gentzen_untersuchungen_1935-1,
	title = {Untersuchungen über das logische {Schließen}. {II}},
	volume = {39},
	number = {1},
	journal = {Mathematische Zeitschrift},
	author = {Gentzen, Gerhard},
	year = {1935},
	note = {Publisher: Springer},
	pages = {405--431},
}

@book{brouwer_intuitionism_1913,
	title = {Intuitionism and formalism},
	publisher = {na},
	author = {Brouwer, Luitzen Egbertus Jan and {others}},
	year = {1913},
}

@article{curry_functionality_1934,
	title = {Functionality in {Combinatory} {Logic}},
	volume = {20},
	issn = {0027-8424},
	url = {https://www.pnas.org/content/20/11/584},
	doi = {10.1073/pnas.20.11.584},
	number = {11},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Curry, H. B.},
	year = {1934},
	note = {Publisher: National Academy of Sciences
\_eprint: https://www.pnas.org/content/20/11/584.full.pdf},
	pages = {584--590},
}

@article{patterson_knowledge_2017,
	title = {Knowledge {Representation} in {Bicategories} of {Relations}},
	volume = {abs/1706.00526},
	journal = {ArXiv},
	author = {Patterson, Evan},
	year = {2017},
}

@book{rademaker_proof_2012,
	title = {A proof theory for description logics},
	publisher = {Springer Science \& Business Media},
	author = {Rademaker, Alexandre},
	year = {2012},
}

@incollection{baader_basic_2003,
	address = {USA},
	title = {Basic {Description} {Logics}},
	isbn = {0-521-78176-0},
	booktitle = {The {Description} {Logic} {Handbook}: {Theory}, {Implementation}, and {Applications}},
	publisher = {Cambridge University Press},
	author = {Baader, Franz and Nutt, Werner},
	year = {2003},
	pages = {43--95},
}

@book{nlab_authors_adjoint_2020,
	title = {adjoint functor},
	url = {http://ncatlab.org/nlab/show/adjoint%20functor},
	author = {{nLab authors}},
	year = {2020},
	annote = {http://ncatlab.org/nlab/revision/adjoint\%20functor/95Revision 95},
}

@book{nlab_authors_galois_2020,
	title = {Galois connection},
	url = {http://ncatlab.org/nlab/show/Galois%20connection},
	author = {{nLab authors}},
	year = {2020},
	annote = {http://ncatlab.org/nlab/revision/Galois\%20connection/22Revision 22},
}

@book{pierce_basic_1991,
	title = {Basic {Category} {Theory} for {Computer} {Scientists}},
	isbn = {978-0-262-28846-0},
	url = {https://direct.mit.edu/books/book/3949/basic-category-theory-for-computer-scientists},
	language = {en},
	urldate = {2020-03-09},
	publisher = {The MIT Press},
	author = {Pierce, Benjamin C.},
	year = {1991},
	doi = {10.7551/mitpress/1524.001.0001},
}

@book{lane_categories_1998,
	series = {Graduate {Texts} in {Mathematics}},
	title = {Categories for the {Working} {Mathematician}},
	isbn = {978-0-387-98403-2},
	url = {https://books.google.com.tw/books?id=eBvhyc4z8HQC},
	publisher = {Springer New York},
	author = {Lane, S.M.},
	year = {1998},
	lccn = {97045229},
}

@misc{noauthor_yoneda_nodate,
	title = {The {Yoneda} {Perspective}},
	url = {https://www.math3ma.com/blog/the-yoneda-perspective},
	urldate = {2020-03-18},
	note = {Library Catalog: www.math3ma.com},
	file = {Snapshot:/Users/wanchengsyuan/Zotero/storage/DDUPZVB2/the-yoneda-perspective.html:text/html},
}

@book{gold_proof_2009,
	address = {Washington DC},
	title = {Proof and other {Dilemmas}: {Mathematics} and {Philosophy}},
	isbn = {978-1-61444-505-0},
	shorttitle = {Proof and other {Dilemmas}},
	url = {http://universitypublishingonline.org/ref/id/maa/CBO9781614445050},
	language = {en},
	urldate = {2020-03-18},
	publisher = {The Mathematical Association of America},
	author = {Gold, Bonnie and Simons, Roger},
	year = {2009},
	doi = {10.5948/UPO9781614445050},
	file = {Gold 與 Simons - 2009 - Proof and other Dilemmas Mathematics and Philosop.pdf:/Users/wanchengsyuan/Zotero/storage/AIKIKVDZ/Gold 與 Simons - 2009 - Proof and other Dilemmas Mathematics and Philosop.pdf:application/pdf},
}

@article{bilkova_how_2020,
	title = {How to reason with inconsistent probabilistic information?},
	url = {http://arxiv.org/abs/2003.12906},
	abstract = {A recent line of research has developed around logics of belief based on information confirmed by a reliable source. In this paper, we provide a finer analysis and extension of this framework, where the confirmation comes from multiple possibly conflicting sources and is of a probabilistic nature. We combine Belnap-Dunn logic and non-standard probabilities to account for potentially contradictory information within a two-layer modal logical framework to account for belief. The bottom layer is to be that of evidence represented by probabilistic information provided by sources available to an agent. The modalities connecting the bottom layer to the top layer, are that of belief of the agent based on the information from the sources in terms of (various kinds of) aggregation. The top layer is to be the logic of thus formed beliefs.},
	urldate = {2020-04-05},
	journal = {arXiv:2003.12906 [cs]},
	author = {Bílková, Marta and Frittella, Sabine and Majer, Ondrej and Nazari, Sajad},
	month = mar,
	year = {2020},
	note = {arXiv: 2003.12906},
	keywords = {Computer Science - Logic in Computer Science},
	file = {arXiv Fulltext PDF:/Users/wanchengsyuan/Zotero/storage/K9B9KGJE/Bílková 等。 - 2020 - How to reason with inconsistent probabilistic info.pdf:application/pdf;arXiv.org Snapshot:/Users/wanchengsyuan/Zotero/storage/7SNTBIAV/2003.html:text/html},
}

@incollection{basin_model_2018,
	address = {Cham},
	title = {Model {Checking} {Security} {Protocols}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_22},
	abstract = {The formal analysis of security protocols is a prime example of a domain where model checking has been successfully applied. Although security protocols are typically small, analysis by hand is difficult as a protocol should work even when arbitrarily many runs are interleaved and in the presence of an adversary. Specialized model-checking techniques have been developed that address both the problems of unbounded, interleaved runs and a prolific, highly nondeterministic adversary. These techniques have been implemented in model-checking tools that now scale to protocols of realistic size and can be used to aid protocol design and standardization.In this chapter, we provide an overview of the main applications of model checking in security protocol analysis. We explain the central concepts involved in the analysis of security protocols: the abstraction of messages, protocols as role automata, the adversary model, and property specification. We explain and relate the main algorithms used and describe systems based on them. We also give examples of the successful applications of model checking to protocol standards. Finally, we provide an outlook on the field: What is possible with the state of the art and what are the future challenges?},
	language = {en},
	urldate = {2020-04-22},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Basin, David and Cremers, Cas and Meadows, Catherine},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_22},
	pages = {727--762},
}

@incollection{clarke_introduction_2018,
	address = {Cham},
	title = {Introduction to {Model} {Checking}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_1},
	abstract = {Model checking is a computer-assisted method for the analysis of dynamical systems that can be modeled by state-transition systems. Drawing from research traditions in mathematical logic, programming languages, hardware design, and theoretical computer science, model checking is now widely used for the verification of hardware and software in industry. This chapter is an introduction and short survey of model checking. The chapter aims to motivate and link the individual chapters of the handbook, and to provide context for readers who are not familiar with model checking.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_1},
	pages = {1--26},
}

@incollection{clarke_introduction_2018-1,
	address = {Cham},
	title = {Introduction to {Model} {Checking}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_1},
	abstract = {Model checking is a computer-assisted method for the analysis of dynamical systems that can be modeled by state-transition systems. Drawing from research traditions in mathematical logic, programming languages, hardware design, and theoretical computer science, model checking is now widely used for the verification of hardware and software in industry. This chapter is an introduction and short survey of model checking. The chapter aims to motivate and link the individual chapters of the handbook, and to provide context for readers who are not familiar with model checking.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_1},
	pages = {1--26},
}

@incollection{holzmann_explicit-state_2018,
	address = {Cham},
	title = {Explicit-{State} {Model} {Checking}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_5},
	abstract = {In this chapter we discuss the methodology used in explicit-state logic model checking, specifically as applied to asynchronous software systems. As the name indicates, in an explicit-state model checker the state descriptor for a system is maintained in explicit, and not symbolic, form, as are all state transitions. Abstraction techniques and partial-order reduction algorithms are used to reduce the search space to a minimum, and advanced storage techniques can be used to extend the reach of this form of verification to very large system sizes. The basic algorithms for explicit-state model checking date from the late 1970s and early 1980s. More advanced versions of these algorithms remain an active area of research.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Holzmann, Gerard J.},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_5},
	pages = {153--171},
}

@incollection{chaki_bdd-based_2018,
	address = {Cham},
	title = {{BDD}-{Based} {Symbolic} {Model} {Checking}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_8},
	abstract = {Symbolic model checking based on Binary Decision Diagrams (BDDs) is one of the most celebrated breakthroughs in the area of formal verification. It was originally proposed in the context of hardware model checking, and advanced the state of the art in model-checking capability by several orders of magnitude in terms of the sizes of state spaces that could be explored successfully. More recently, it has been extended to the domain of software verification as well, and several BDD-based model checkers for Boolean programs and push-down systems have been developed. In this chapter, we summarize some of the key concepts and techniques that have emerged in this story of successful practical verification.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Chaki, Sagar and Gurfinkel, Arie},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_8},
	pages = {219--245},
}

@incollection{seshia_modeling_2018,
	address = {Cham},
	title = {Modeling for {Verification}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_3},
	abstract = {System modeling is the initial, and often crucial, step in verification. The right choice of model and modeling language is important for both designers and users of verification tools. This chapter aims to provide a guide to system modeling in four stages. First, it provides an overview of the main issues one must consider in modeling systems for verification. These issues involve both the selection or design of a modeling language and the steps of model creation. Next, it introduces a simple modeling language, sml, for illustrating the issues involved in selecting or designing a modeling language. sml uses an abstract state machine formalism that captures key features of widely-used languages based on transition system representations. We introduce the simple modeling language to simplify the connection between languages used by practitioners (such as Verilog, Simulink, or C) and various underlying formalisms (e.g., automata or Kripke structures) used in model checking. Third, the chapter demonstrates key steps in model creation using sml with illustrative examples. Finally, the presented modeling language sml is mapped to standard formalisms such as Kripke structures.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Seshia, Sanjit A. and Sharygina, Natasha and Tripakis, Stavros},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_3},
	pages = {75--105},
}

@incollection{peled_partial-order_2018,
	address = {Cham},
	title = {Partial-{Order} {Reduction}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_6},
	abstract = {Partial order reduction methods help reduce the time and space required to automatically verify concurrent asynchronous systems based on commutativity between concurrently executed transitions. We describe partial order reduction for various specification formalisms, such as LTL, CTL, and process algebra.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Peled, Doron},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_6},
	pages = {173--190},
}

@incollection{piterman_temporal_2018,
	address = {Cham},
	title = {Temporal {Logic} and {Fair} {Discrete} {Systems}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_2},
	abstract = {Temporal logic has been used by philosophers to reason about the way the world changes over time. Its modern use in specification and verification of systems describes the evolution of states of a program/design giving rise to descriptions of executions. Temporal logics can be classified by their view of the evolution of time as either linear or branching. In the linear-time view, we see time ranging over a linear total order and executions are sequences of states. When the system has multiple possible executions (due to nondeterminism or reading input) we view them as separate possible evolutions and the system has a set of possible behaviors. In the branching-time view, a point in time may have multiple possible successors and accordingly executions are tree-like structures. According to this view, a system has exactly one execution, which takes the form of a tree. We start this chapter by introducing Fair Discrete Structures, the model on which we evaluate the truth and falsity of temporal logic formulas. Fair Discrete Structures describe the states of a system and their possible evolution. We then proceed with the linear-time view and introduce Propositional Linear Temporal Logic (LTL). We explain the distinction between safety and liveness properties and introduce a hierarchy of liveness properties of increasing expressiveness. We study the expressive power of full LTL and cover extensions that increase its expressive power. We introduce algorithms for checking the satisfiability of LTL and model checking LTL. We turn to the branching-time framework and introduce Computation Tree Logic (CTL). As before, we discuss its expressive power, consider extensions, and cover satisfiability and model checking. We then dedicate some time to examples of formulas in both LTL and CTL and stress the differences between the two. We end with a formal comparison of LTL and CTL and, in view of this comparison, introduce CTL*, a hybrid of LTL and CTL that combines the linear and branching views into one logic.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Piterman, Nir and Pnueli, Amir},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_2},
	pages = {27--73},
}

@incollection{bryant_binary_2018,
	address = {Cham},
	title = {Binary {Decision} {Diagrams}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_7},
	abstract = {Binary decision diagrams provide a data structure for representing and manipulating Boolean functions in symbolic form. They have been especially effective as the algorithmic basis for symbolic model checkers. A binary decision diagram represents a Boolean function as a directed acyclic graph, corresponding to a compressed form of decision tree. Most commonly, an ordering constraint is imposed among the occurrences of decision variables in the graph, yielding ordered binary decision diagrams (OBDD). Representing all functions as OBDDs with a common variable ordering has the advantages that (1) there is a unique, reduced representation of any function, (2) there is a simple algorithm to reduce any OBDD to the unique form for that function, and (3) there is an associated set of algorithms to implement a wide variety of operations on Boolean functions represented as OBDDs. Recent work in this area has focused on generalizations to represent larger classes of functions, as well as on scaling implementations to handle larger and more complex problems.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Bryant, Randal E.},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_7},
	pages = {191--217},
}

@incollection{marques-silva_propositional_2018,
	address = {Cham},
	title = {Propositional {SAT} {Solving}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_9},
	abstract = {The Boolean Satisfiability Problem (SAT) is well known in computational complexity, representing the first decision problem to be proved NP-complete. SAT is also often the subject of work in proof complexity. Besides its theoretical interest, SAT finds a wide range of practical applications. Moreover, SAT solvers have been the subject of remarkable efficiency improvements since the mid-1990s, motivating their widespread use in many practical applications including Bounded and Unbounded Model Checking. The success of SAT solvers has also motivated the development of algorithms for natural extensions of SAT, including Quantified Boolean Formulas (QBF), Pseudo-Boolean constraints (PB), Maximum Satisfiability (MaxSAT) and Satisfiability Modulo Theories (SMT) which also see application in the model-checking context. This chapter first covers the organization of modern conflict-driven clause learning (CDCL) SAT solvers, which are used in the vast majority of practical applications of SAT. It then reviews the techniques shown to be effective in modern SAT solvers.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Marques-Silva, Joao and Malik, Sharad},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_9},
	pages = {247--275},
}

@incollection{kupferman_automata_2018,
	address = {Cham},
	title = {Automata {Theory} and {Model} {Checking}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_4},
	abstract = {We study automata on infinite words and their applications in system specification and verification. We first introduce Büchi automata and survey their closure properties, expressive power, and determinization. We then introduce additional acceptance conditions and the model of alternating automata. We compare the different classes of automata in terms of expressive power and succinctness, and describe decision problems for them. Finally, we describe the automata-theoretic approach to system specification and verification.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Kupferman, Orna},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_4},
	pages = {107--151},
}

@incollection{basin_model_2018-1,
	address = {Cham},
	title = {Model {Checking} {Security} {Protocols}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_22},
	abstract = {The formal analysis of security protocols is a prime example of a domain where model checking has been successfully applied. Although security protocols are typically small, analysis by hand is difficult as a protocol should work even when arbitrarily many runs are interleaved and in the presence of an adversary. Specialized model-checking techniques have been developed that address both the problems of unbounded, interleaved runs and a prolific, highly nondeterministic adversary. These techniques have been implemented in model-checking tools that now scale to protocols of realistic size and can be used to aid protocol design and standardization.In this chapter, we provide an overview of the main applications of model checking in security protocol analysis. We explain the central concepts involved in the analysis of security protocols: the abstraction of messages, protocols as role automata, the adversary model, and property specification. We explain and relate the main algorithms used and describe systems based on them. We also give examples of the successful applications of model checking to protocol standards. Finally, we provide an outlook on the field: What is possible with the state of the art and what are the future challenges?},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Basin, David and Cremers, Cas and Meadows, Catherine},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_22},
	pages = {727--762},
}

@incollection{giannakopoulou_compositional_2018,
	address = {Cham},
	title = {Compositional {Reasoning}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_12},
	abstract = {State Explosion is a fundamental challenge for model checking methods. This term refers to the potentially exponential growth of the state space of a program as a function of the number of its components. Compositional reasoning is a technique which aims to ameliorate the effects of state explosion. In its essence, it replaces reasoning on the global state space of a program with localized reasoning: each component is analyzed separately, based on assumptions about the behavior of the other components. The challenge for a fully automated method is the construction of the right assumptions: they should be strong enough to prove a desired property, while being simple enough for efficient analysis. This chapter describes the ideas underlying compositional reasoning, foundational algorithms for generating assumptions, and applications.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Giannakopoulou, Dimitra and Namjoshi, Kedar S. and Păsăreanu, Corina S.},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_12},
	pages = {345--383},
}

@incollection{dams_abstraction_2018,
	address = {Cham},
	title = {Abstraction and {Abstraction} {Refinement}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_13},
	abstract = {Abstraction, in the context of model checking, is aimed at reducing the state space of the system by omitting details that are irrelevant to the property being verified. Many successful approaches to the “state explosion problem,” some of them described in other chapters, can be seen as abstractions. In this chapter, several notions of abstraction are considered in a uniform setting. Different such notions lead to a variety of preservation results that establish which kind of temporal properties may be verified via an abstracted system. We first define the needed background on simulation and bisimulation relations and their logic preservation. We then present the abstraction that is currently most widely used in practice: existential abstraction, which preserves universal fragments of branching-time logics. We give examples of such abstractions: localization reduction for hardware and predicate abstraction for software. We then proceed to stronger abstractions which preserve full branching-time logics. We introduce Kripke Modal Transition Systems and modal simulation, and show logic preservation. We close the chapter with a review of the presented results in the light of the notion of completeness.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Dams, Dennis and Grumberg, Orna},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_13},
	pages = {385--419},
}

@incollection{mcmillan_interpolation_2018,
	address = {Cham},
	title = {Interpolation and {Model} {Checking}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_14},
	abstract = {In this chapter we consider applications of logical proofs in model checking. Here we are not concerned with using model checking to verify steps in a larger proof but rather with ways in which logical proof methods can aid model checking, particularly in focusing model-checking methods on relevant facts. We introduce a framework for abstraction refinement based on a concept of deductive generalization. We then show how various abstraction refinement schemes can be understood in this framework in terms of local proofs and Craig interpolation. This unifying view exposes the trade-offs made in different systems between the quality and cost of refinements, and also leads to novel model-checking approaches.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {McMillan, Kenneth L.},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_14},
	pages = {421--446},
}

@incollection{biere_sat-based_2018,
	address = {Cham},
	title = {{SAT}-{Based} {Model} {Checking}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_10},
	abstract = {Modern satisfiability (SAT) solvers have become the enabling technology of many model checkers. In this chapter, we will focus on those techniques most relevant to industrial practice. In bounded model checking (BMC), a transition system and a property are jointly unwound for a given number {\textbackslash}(k{\textbackslash}) of steps to obtain a formula that is satisfiable if there is a counterexample for the property up to length {\textbackslash}(k{\textbackslash}). The formula is then passed to an efficient SAT solver. The strength of BMC is refutation: BMC has been used to discover subtle flaws in digital systems. We cover the application of BMC to both hardware and software systems, and to hardware/software co-verification. We also discuss means to make BMC complete, including {\textbackslash}(k{\textbackslash})-induction, Craig interpolation, abstraction refinement techniques, and inductive techniques with iterative strengthening.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Biere, Armin and Kröning, Daniel},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_10},
	pages = {277--303},
}

@incollection{jhala_predicate_2018,
	address = {Cham},
	title = {Predicate {Abstraction} for {Program} {Verification}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_15},
	abstract = {We present basic principles of algorithms for the verification of safety and termination of programs. The algorithms call procedures on logical formulas in order to construct an abstraction and to refine an abstraction. The two underlying concepts are predicate abstraction and counterexample-guided abstraction refinement.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Jhala, Ranjit and Podelski, Andreas and Rybalchenko, Andrey},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_15},
	pages = {447--491},
}

@incollection{barrett_satisfiability_2018,
	address = {Cham},
	title = {Satisfiability {Modulo} {Theories}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_11},
	abstract = {Satisfiability Modulo Theories (SMT) refers to the problem of determining whether a first-order formula is satisfiable with respect to some logical theory. Solvers based on SMT are used as back-end engines in model-checking applications such as bounded, interpolation-based, and predicate-abstraction-based model checking. After a brief illustration of these uses, we survey the predominant techniques for solving SMT problems with an emphasis on the lazy approach, in which a propositional satisfiability (SAT) solver is combined with one or more theory solvers. We discuss the architecture of a lazy SMT solver, give examples of theory solvers, show how to combine such solvers modularly, and mention several extensions of the lazy approach. We also briefly describe the eager approach in which the SMT problem is reduced to a SAT problem. Finally, we discuss how the basic framework for determining satisfiability can be extended with additional functionality such as producing models, proofs, unsatisfiable cores, and interpolants.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Barrett, Clark and Tinelli, Cesare},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_11},
	pages = {305--343},
}

@incollection{gupta_model_2018,
	address = {Cham},
	title = {Model {Checking} {Concurrent} {Programs}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_18},
	abstract = {Concurrent programs are in widespread use for harnessing the computing power of multi-core hardware. However, it is very challenging to develop correct concurrent programs. In practice, concurrency-related bugs such as data races, deadlocks, and atomicity violations are very common. In this chapter, we describe efforts based on model-checking for automatic verification and debugging of concurrent programs. The emphasis is on core ideas for reasoning about synchronizations and communication between threads and processes, while considering all possible behaviors due to their interactions.We start by considering model-checking based on interacting pushdown system (PDS) models. In these models, each component (thread or process) is modeled as a pushdown automaton, where the stack is used to model recursion. Model checking based on pushdown automata has a close correspondence with dataflow analysis of programs, and this has been successfully used for verification of sequential programs. However, applying these methods to a system of interacting pushdown automata is not straightforward. Even the basic problem of reachability is undecidable in the general case. We describe some techniques that have been proposed to get around this barrier, by restricting the patterns of synchronization and communication among components.Although PDSs provide a natural model for concurrent programs, it is difficult to apply PDS-based model-checking techniques directly to concurrent programs in practice. In addition to the formidable decidability barrier, this is also due to the huge gap between low-level PDS models and the feature-rich high-level programming languages in which concurrent programs are written. Fortunately, the successes of model-checking on finite state systems and sequential programs have provided a wealth of useful abstractions and techniques to bridge this gap. In the last part of the chapter, we will describe verification techniques for concurrent programs that are inspired by these models. They often abstract the effects of synchronization and focus on handling the complexity of reasoning about all possible behaviors. However, they can, and should, exploit insights and results of PDS-based model-checking.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Gupta, Aarti and Kahlon, Vineet and Qadeer, Shaz and Touili, Tayssir},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_18},
	pages = {573--611},
}

@incollection{beyer_combining_2018,
	address = {Cham},
	title = {Combining {Model} {Checking} and {Data}-{Flow} {Analysis}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_16},
	abstract = {Until recently, model checking and data-flow analysis—two traditional approaches to software verification—were used independently and in isolation for solving similar problems. Theoretically, the two different approaches are equivalent; they are two different ways to compute the same solution to a problem. In recent years, new practical approaches have shown how to combine the approaches and how to make them benefit from each other—model-checking techniques can make data-flow analyses more precise, and data-flow-analysis techniques can make model checking more efficient. This chapter starts by discussing the relationship (differences and similarities) between type checking, data-flow analysis, and model checking. Then we define algorithms for data-flow analysis and model checking in the same formal setting, called configurable program analysis. This identifies key differences that make us call an algorithm a “model-checking” algorithm or a “data-flow-analysis” algorithm. We illustrate the effect of using different algorithms for running certain classic example analyses and point out the reason for one algorithm being “better” than the other. The chapter presents combined verification techniques in the framework of configurable program analysis, in order to emphasize techniques used in data-flow analysis and in model checking. Besides the iterative algorithm that is used to illustrate the similarities and differences between data-flow analysis and model checking, we discuss different algorithmic approaches for constructing program invariants. To show that the border between data-flow analysis and model checking is blurring and disappearing, we also discuss directions in tool implementations for combined verification approaches.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Beyer, Dirk and Gulwani, Sumit and Schmidt, David A.},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_16},
	pages = {493--540},
}

@incollection{alur_model_2018,
	address = {Cham},
	title = {Model {Checking} {Procedural} {Programs}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_17},
	abstract = {We consider the model-checking problem for sequential programs with procedure calls. We first present basic algorithms for solving the reachability problem and the fair computation problem. The algorithms are based on two techniques: summarization, which computes reachability information by solving a set of fixpoint equations, and saturation, which computes the set of all reachable program states (including call stacks) using automata. Then, we study formalisms to specify requirements of programs with procedure calls. We present an extension of Linear Temporal Logic allowing propagation of information across the hierarchical structure induced by procedure calls and matching returns. Finally, we show how model checking can be extended to this class of programs and properties.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Alur, Rajeev and Bouajjani, Ahmed and Esparza, Javier},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_17},
	pages = {541--572},
}

@incollection{shankar_combining_2018,
	address = {Cham},
	title = {Combining {Model} {Checking} and {Deduction}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_20},
	abstract = {There are two basic approaches to automated verification. In model checking, the system is viewed as a graph representing possible execution steps. Properties are established by exploring or traversing the graph structure. In deduction, both the system and its putative properties are represented by formulas in a logic, and the resulting proof obligations are discharged by decision procedures or by automated or semi-automated proof construction. Model checking sacrifices expressivity for greater automation, and with deduction it is vice versa. Newer techniques combine deductive and model-checking approaches to achieve greater scale, expressivity, and automation. We examine the logical foundations of the two approaches and explore their similarities, differences, and complementarities. The presentation is directed at students and researchers who are interested in understanding the research challenges at the intersection of deduction and model checking.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Shankar, Natarajan},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_20},
	pages = {651--684},
}

@incollection{godefroid_combining_2018,
	address = {Cham},
	title = {Combining {Model} {Checking} and {Testing}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_19},
	abstract = {Model checking and testing have a lot in common. Over the last two decades, significant progress has been made on how to broaden the scope of model checking from finite-state abstractions to actual software implementations. One way to do this consists of adapting model checking into a form of systematic testing that is applicable to industrial-size software. This chapter presents an overview of this strand of software model checking.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Godefroid, Patrice and Sen, Koushik},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_19},
	pages = {613--649},
}

@incollection{abdulla_model_2018,
	address = {Cham},
	title = {Model {Checking} {Parameterized} {Systems}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_21},
	abstract = {We consider the model-checking problem for a particular class of parameterized systems: systems that consist of arbitrary numbers of components. The task is to show correctness regardless of the number of components. The term parameterized refers to the fact that the size of the system is a parameter of the verification problem. Examples of parameterized systems include mutual exclusion algorithms, bus protocols, networking protocols, cache coherence protocols, web services, and sensor networks. In this chapter, we will give four examples of techniques that have been used (among many others) for the verification of parameterized systems.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Abdulla, Parosh Aziz and Sistla, A. Prasad and Talupur, Muralidhar},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_21},
	pages = {685--725},
}

@incollection{kurshan_transfer_2018,
	address = {Cham},
	title = {Transfer of {Model} {Checking} to {Industrial} {Practice}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_23},
	abstract = {This chapter traces the practical challenges that were overcome in order to transfer model-checking theory to industrial practice. In retrospect, this transfer provided a lesson in how to, and how not to accomplish technology transfer. The methodology changes required for industrial model checking were achieved through a succession of steps, each of which was small enough to avoid unacceptable disruption of existing methodologies, while significant enough to demonstrate value.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Kurshan, Robert P.},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_23},
	pages = {763--793},
}

@incollection{melham_symbolic_2018,
	address = {Cham},
	title = {Symbolic {Trajectory} {Evaluation}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_25},
	abstract = {Symbolic trajectory evaluation is an industrial-strength formal hardware verification method, based on symbolic simulation, which has been highly successful in data-path verification, especially for microprocessor execution units. It is a ‘model-checking’ method in the basic sense that properties, expressed in a simple temporal logic, are verified by (symbolic) exploration of formal models of sequential circuits. Its defining characteristic is that it operates by symbolic simulation over abstractions of sets of states that only partially delineate the circuit states in the set. These abstract state sets are ordered in a lattice by information content, based on a three-valued domain for values on circuit nodes (true, false, and don’t know). The algorithm operates over families of these abstractions encoded by Boolean formulas, providing a flexible, specification-driven mechanism for partitioned data abstraction. We provide a basic introduction to symbolic trajectory evaluation and its extensions, and some details of how it is deployed in industrial practice. The aim is to get across the essence and value of the method in clear and accessible terms.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Melham, Tom},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_25},
	pages = {831--870},
}

@incollection{eisner_functional_2018,
	address = {Cham},
	title = {Functional {Specification} of {Hardware} via {Temporal} {Logic}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_24},
	abstract = {In the late 1970s, Amir Pnueli suggested that functional properties of reactive systems be formally expressed in temporal logic. For model checking such a logic to be possible, it must have sufficient expressive power, its semantics must be formally defined in a rigorous way, and the complexity of model checking it must be well understood and reasonable. In order to allow widespread adoption in industry, there is an additional requirement: functional specification must be made easy, allowing common properties to be expressed intuitively and succinctly. But while adding syntax is simple, defining semantics without breaking properties of the existing semantics is a different story. This chapter is about the various extensions to temporal logic included in the IEEE standards PSL and SVA, their motivation, and the subtle semantic issues encountered in their definition.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Eisner, Cindy and Fisman, Dana},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_24},
	pages = {795--829},
}

@incollection{bradfield_mu-calculus_2018,
	address = {Cham},
	title = {The mu-calculus and {Model} {Checking}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_26},
	abstract = {This chapter presents that part of the theory of the {\textbackslash}({\textbackslash}mu{\textbackslash})-calculus that is relevant to the model-checking problem as broadly understood. The {\textbackslash}({\textbackslash}mu{\textbackslash})-calculus is one of the most important logics in model checking. It is a logic with an exceptional balance between expressiveness and algorithmic properties.The chapter describes at length the game characterization of the semantics of the {\textbackslash}({\textbackslash}mu{\textbackslash})-calculus. It discusses the theory of the {\textbackslash}({\textbackslash}mu{\textbackslash})-calculus starting with the tree-model property, and bisimulation invariance. Then it develops the notion of modal automaton: an automaton-based model behind the {\textbackslash}({\textbackslash}mu{\textbackslash})-calculus. It gives a quite detailed explanation of the satisfiability algorithm, followed by results on alternation hierarchy, proof systems, and interpolation. Finally, the chapter discusses the relation of the {\textbackslash}({\textbackslash}mu{\textbackslash})-calculus to monadic second-order logic as well as to some program and temporal logics. It also presents two extensions of the {\textbackslash}({\textbackslash}mu{\textbackslash})-calculus that allow us to address issues such as inverse modalities.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Bradfield, Julian and Walukiewicz, Igor},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_26},
	pages = {871--919},
	file = {Submitted Version:/Users/wanchengsyuan/Zotero/storage/9ERU8DNS/Bradfield 與 Walukiewicz - 2018 - The mu-calculus and Model Checking.pdf:application/pdf},
}

@incollection{bloem_graph_2018,
	address = {Cham},
	title = {Graph {Games} and {Reactive} {Synthesis}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_27},
	abstract = {Graph-based games are an important tool in computer science. They have applications in synthesis, verification, refinement, and far beyond. We review graph-based games with objectives on infinite plays. We give definitions and algorithms to solve the games and to give a winning strategy. The objectives we consider are mostly Boolean, but we also look at quantitative graph-based games and their objectives. Synthesis aims to turn temporal logic specifications into correct reactive systems. We explain the reduction of synthesis to graph-based games (or equivalently tree automata) using synthesis of LTL specifications as an example. We treat the classical approach that uses determinization of parity automata and more modern approaches.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Bloem, Roderick and Chatterjee, Krishnendu and Jobstmann, Barbara},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_27},
	pages = {921--962},
}

@incollection{baier_model_2018,
	address = {Cham},
	title = {Model {Checking} {Probabilistic} {Systems}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_28},
	abstract = {The model-checking approach was originally formulated for verifying qualitative properties of systems, for example safety and liveness (see Chap. 2), and subsequently extended to also handle quantitative features, such as real time (see Chap. 29), continuous flows (see Chap. 30), as well as stochastic phenomena, where system evolution is governed by a given probability distribution. Probabilistic model checking aims to establish the correctness of probabilistic system models against quantitative probabilistic specifications, such as those capable of expressing, for example, the probability of an unsafe event occurring, expected time to termination, or expected power consumption in the start-up phase. In this chapter, we present the foundations of probabilistic model checking, focusing on finite-state Markov decision processes as models and quantitative properties expressed in probabilistic temporal logic. Markov decision processes can be thought of as a probabilistic variant of labelled transition systems in the following sense: transitions are labelled with actions, which can be chosen nondeterministically, and successor states for the chosen action are specified by means of discrete probabilistic distributions, thus specifying the probability of transiting to each successor state. To reason about expectations, we additionally annotate Markov decision processes with quantitative costs, which are incurred upon taking the selected action from a given state. Quantitative properties are expressed as formulas of the probabilistic computation tree logic (PCTL) or using linear temporal logic (LTL). We summarise the main model-checking algorithms for both PCTL and LTL, and illustrate their working through examples. The chapter ends with a brief overview of extensions to more expressive models and temporal logics, existing probabilistic model-checking tool support, and main application domains.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Baier, Christel and de Alfaro, Luca and Forejt, Vojtěch and Kwiatkowska, Marta},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_28},
	pages = {963--999},
}

@incollection{majumdar_symbolic_2018,
	address = {Cham},
	title = {Symbolic {Model} {Checking} in {Non}-{Boolean} {Domains}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_31},
	abstract = {We consider symbolic model checking as a general procedure to compute fixed points on general lattices. We show that this view provides a unified approach for formal reasoning about systems that is applicable to many different classes of systems and properties. Our unified view is based on the notion of region algebras together with appropriate generalizations of the modal {\textbackslash}({\textbackslash}mu{\textbackslash})-calculus. We show applications of our general approach to problems in infinite-state verification, reactive synthesis, and the analysis of probabilistic systems.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Majumdar, Rupak and Raskin, Jean-François},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_31},
	pages = {1111--1147},
}

@incollection{doyen_verification_2018,
	address = {Cham},
	title = {Verification of {Hybrid} {Systems}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_30},
	abstract = {Hybrid systems are models which combine discrete and continuous behavior. They occur frequently in safety-critical applications in various domains such as health care, transportation, and robotics, as a result of interactions between a digital controller and a physical environment. They also have relevance in other areas such as systems biology, in which the discrete dynamics arises as an abstraction of fast continuous processes. One of the prominent models is that of hybrid automata, where differential equations are associated with each node, and jump constraints such as guards and resets are associated with each edge.In this chapter, we focus on the problem of model checking of hybrid automata against reachability and invariance properties, enabling the verification of general temporal logic specifications. We review the main decidability results for hybrid automata, and since model checking is in general undecidable, we present three complementary analysis approaches based on symbolic representations, abstraction, and logic. In particular, we illustrate polyhedron-based reachability analysis, finite quotients, abstraction refinement techniques, and logic-based verification. We survey important tools and application domains of successful hybrid system verification in this vibrant area of research.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Doyen, Laurent and Frehse, Goran and Pappas, George J. and Platzer, André},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_30},
	pages = {1047--1110},
}

@incollection{bouyer_model_2018,
	address = {Cham},
	title = {Model {Checking} {Real}-{Time} {Systems}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_29},
	abstract = {This chapter surveys timed automata as a formalism for model checking real-time systems. We begin with introducing the model, as an extension of finite-state automata with real-valued variables for measuring time. We then present the main model-checking results in this framework, and give a hint about some recent extensions (namely weighted timed automata and timed games).},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Bouyer, Patricia and Fahrenberg, Uli and Larsen, Kim Guldstrand and Markey, Nicolas and Ouaknine, Joël and Worrell, James},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_29},
	pages = {1001--1046},
	file = {Submitted Version:/Users/wanchengsyuan/Zotero/storage/3LUGUAEZ/Bouyer 等。 - 2018 - Model Checking Real-Time Systems.pdf:application/pdf},
}

@incollection{cleaveland_process_2018,
	address = {Cham},
	title = {Process {Algebra} and {Model} {Checking}},
	isbn = {978-3-319-10575-8},
	url = {https://doi.org/10.1007/978-3-319-10575-8_32},
	abstract = {Process algebras such as CCS, CSP and ACP are abstract notations for describing concurrent systems that interact via (usually) handshake-based communication. They lead to natural concepts of process state and are therefore natural candidates for model checking. We survey the area of process algebra and model checking, focusing on these three process algebras. We first introduce the syntax and semantics of these process algebras, before looking at the algorithmic basis for their model checking, which includes ideas such as bisimulation and refinement as well as the logics used to describe system-correctness properties. Finally, we introduce the process-alebra-based model-checking tools FDR, CWB and XMC, illustrating their utility by a number of case studies.},
	language = {en},
	urldate = {2020-04-24},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Cleaveland, Rance and Roscoe, A. W. and Smolka, Scott A.},
	editor = {Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_32},
	pages = {1149--1195},
}

@inproceedings{de_vos_dynamic_2002,
	title = {Dynamic {Decision}-{Making} in {Logic} {Programming} and {Game} {Theory}},
	doi = {10.1007/3-540-36187-1_4},
	abstract = {We present a framework for decision making with circumstance-de- pendent preferences and decisions. This formalism, called Ordered Choice Logic Programming, allows decisions that comprise multiple alternatives, which be- come available only when a choice between them is forced. The skeptical seman- tics is based on answer sets for which we provide a fixpoint characterization and a bottom-up algorithm. OCLPs can be used to represent and extend game theory concepts. We demonstrate that OCLPs allow an elegant translation of finite ex- tensive games with perfect information such that the c-answer sets correspond to the Nash equilibria of the game. These equilibria are not player-deterministic, in the sense that a single player, given the other players' actions, could rationally leave an equilibrium state by changing her action profile. Therefor cautious Nash equilibria are introduced as the answer sets of the transformed game.},
	author = {De Vos, Marina and Vermeir, Dirk},
	month = dec,
	year = {2002},
	pages = {36--47},
	file = {Full Text PDF:/Users/wanchengsyuan/Zotero/storage/IQDI3FNI/De Vos 與 Vermeir - 2002 - Dynamic Decision-Making in Logic Programming and G.pdf:application/pdf},
}

@misc{ltd_kopernio_nodate,
	title = {Kopernio {\textbar} {Document} {Viewer}},
	url = {https://kopernio.com/viewer?doi=10.1007%2F3-540-36187-1_4&token=WzIwOTc1NzQsIjEwLjEwMDcvMy01NDAtMzYxODctMV80Il0.smge1rAz_O7bkTLfG93y6rMUwcE},
	abstract = {Hit a paywall during your literature search? Can't access library resources while at home or travelling? Tired of googling and chasing links? Try Kopernio for one-click access to PDFs.},
	language = {zh-Hant-TW},
	urldate = {2020-04-29},
	author = {Ltd, Kopernio},
	note = {Library Catalog: kopernio.com},
	file = {Snapshot:/Users/wanchengsyuan/Zotero/storage/L9554S4T/viewer.html:text/html},
}

@article{uustalu_sequent_2018,
	series = {Proceedings of the {Thirty}-{Fourth} {Conference} on the {Mathematical} {Foundations} of {Programming} {Semantics} ({MFPS} {XXXIV})},
	title = {The {Sequent} {Calculus} of {Skew} {Monoidal} {Categories}},
	volume = {341},
	issn = {1571-0661},
	url = {http://www.sciencedirect.com/science/article/pii/S1571066118300987},
	doi = {10.1016/j.entcs.2018.11.017},
	abstract = {Szlachányi's skew monoidal categories are a well-motivated variation of monoidal categories in which the unitors and associator are not required to be natural isomorphisms, but merely natural transformations in a particular direction. We present a sequent calculus for skew monoidal categories, building on the recent formulation by one of the authors of a sequent calculus for the Tamari order (skew semigroup categories). In this calculus, antecedents consist of a stoup (an optional formula) followed by a context (a list of formulae), and the connectives unit and tensor behave like in intuitionistic non-commutative linear logic (the logic of monoidal categories) except that the left rules may only be applied in stoup position. We show the admissibility of two forms cut (stoup cut and context cut), and prove the calculus sound and complete with respect to existence of maps in the free skew monoidal category. We then introduce an equivalence relation on sequent calculus derivations and prove that there is a one-to-one correspondence between equivalence classes of derivations and maps in the free skew monoidal category. Finally, we identify a subcalculus of focused derivations, and establish that it contains exactly one canonical representative from each equivalence class. As an end result, we obtain simple algorithms both for deciding equality of maps in the free skew monoidal category and for enumerating any homset without duplicates, in particular, for deciding whether there is a map. We have formalized this development in the dependently typed programming language Agda.},
	language = {en},
	urldate = {2020-05-04},
	journal = {Electronic Notes in Theoretical Computer Science},
	author = {Uustalu, Tarmo and Veltri, Niccolò and Zeilberger, Noam},
	month = dec,
	year = {2018},
	keywords = {Agda, cut admissibility, focusing, nonstandard sequent forms, sequent calculus, skew monoidal categories, substructural logics},
	pages = {345--370},
	file = {ScienceDirect Snapshot:/Users/wanchengsyuan/Zotero/storage/5ZTLAQQG/S1571066118300987.html:text/html;ScienceDirect Full Text PDF:/Users/wanchengsyuan/Zotero/storage/TEQEG34U/Uustalu 等。 - 2018 - The Sequent Calculus of Skew Monoidal Categories.pdf:application/pdf},
}

@inproceedings{lambek_deductive_1972,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Mathematics}},
	title = {Deductive systems and categories {III}. {Cartesian} closed categories, intuitionist propositional calculus, and combinatory logic},
	isbn = {978-3-540-37609-5},
	doi = {10.1007/BFb0073965},
	language = {en},
	booktitle = {Toposes, {Algebraic} {Geometry} and {Logic}},
	publisher = {Springer},
	author = {Lambek, Joachim},
	editor = {Bucur, I. and Giraud, J. and Goodman, N. and Myhill, J. and Illusie, L. and Lambek, J. and Scott, D. S. and Tierney, M. and Lawvere, F. W.},
	year = {1972},
	keywords = {Combinatory Logic, Deductive System, Intuitionist Logic, Left Adjoint, Propositional Calculus},
	pages = {57--82},
}

@article{lack_triangulations_2014,
	title = {Triangulations, orientals, and skew monoidal categories},
	volume = {258},
	issn = {0001-8708},
	url = {https://dx.doi.org/10.1016/j.aim.2014.03.003},
	doi = {10.1016/j.aim.2014.03.003},
	journal = {Advances in Mathematics},
	author = {Lack, Stephen and Street, Ross},
	year = {2014},
	note = {Publisher: Elsevier BV},
	pages = {351--396},
	file = {Lack-2014-Triangulations-orientals-and-skew-m:/Users/wanchengsyuan/Zotero/storage/GD629YAN/Lack-2014-Triangulations-orientals-and-skew-m.pdf:application/pdf},
}

@article{uustalu_sequent_2018-1,
	title = {The {Sequent} {Calculus} of {Skew} {Monoidal} {Categories}},
	volume = {341},
	issn = {1571-0661},
	url = {https://dx.doi.org/10.1016/j.entcs.2018.11.017},
	doi = {10.1016/j.entcs.2018.11.017},
	journal = {Electronic Notes in Theoretical Computer Science},
	author = {Uustalu, Tarmo and Veltri, Niccolò and Zeilberger, Noam},
	year = {2018},
	note = {Publisher: Elsevier BV},
	pages = {345--370},
	file = {Uustalu et al. - 2018 - The Sequent Calculus of Skew Monoidal Categories.pdf:/Users/wanchengsyuan/Zotero/storage/4QSFPE3F/Uustalu et al. - 2018 - The Sequent Calculus of Skew Monoidal Categories.pdf:application/pdf},
}

@article{szlachanyi_skew-monoidal_2012,
	title = {Skew-monoidal categories and bialgebroids},
	volume = {231},
	issn = {0001-8708},
	url = {https://dx.doi.org/10.1016/j.aim.2012.06.027},
	doi = {10.1016/j.aim.2012.06.027},
	number = {3-4},
	author = {Szlachányi, Kornél},
	year = {2012},
	note = {Publisher: Elsevier BV},
	pages = {1694--1730},
	file = {Szlachanyi-2012-Skew-monoidal-categories-and-bialge:/Users/wanchengsyuan/Zotero/storage/XJ9UHVH9/Szlachanyi-2012-Skew-monoidal-categories-and-bialge.pdf:application/pdf},
}

@article{pinto_proof-theoretic_2018,
	title = {A proof-theoretic study of bi-intuitionistic propositional sequent calculus},
	volume = {28},
	issn = {0955-792X, 1465-363X},
	url = {https://academic.oup.com/logcom/article/28/1/165/4807375},
	doi = {10.1093/logcom/exx044},
	abstract = {Bi-intuitionistic logic is the conservative extension of intuitionistic logic with a connective dual to implication usually called ‘exclusion’. A standard-style sequent calculus for this logic is easily obtained by extending multiple-conclusion sequent calculus for intuitionistic logic with exclusion rules dual to the implication rules (in particular, the exclusion-left rule restricts the premise to be single-assumption). However, similarly to standard-style sequent calculi for non-classical logics like S5, this calculus is incomplete without the cut rule. Motivated by the problem of proof search for propositional bi-intuitionistic logic (BiInt), various cut-free calculi with extended sequents have been proposed, including (i) a calculus of nested sequents by Goré et al., which includes rules for creation and removal of nests (called ‘nest rules’, resp. ‘unnest rules’) and (ii) a calculus of labelled sequents by the authors, derived from the Kripke semantics of BiInt, which includes ‘monotonicity rules’ to propagate truth/falsehood between accessible worlds.},
	language = {en},
	number = {1},
	urldate = {2020-12-08},
	journal = {Journal of Logic and Computation},
	author = {Pinto, Luís and Uustalu, Tarmo},
	month = feb,
	year = {2018},
	pages = {165--202},
	file = {Pinto and Uustalu - 2018 - A proof-theoretic study of bi-intuitionistic propo.pdf:/Users/wanchengsyuan/Zotero/storage/LUC5WBTL/Pinto and Uustalu - 2018 - A proof-theoretic study of bi-intuitionistic propo.pdf:application/pdf},
}

@article{uustalu_coherence_2014,
	title = {Coherence for {Skew}-{Monoidal} {Categories}},
	volume = {153},
	issn = {2075-2180},
	url = {http://arxiv.org/abs/1406.2064},
	doi = {10.4204/EPTCS.153.5},
	abstract = {I motivate a variation (due to K. Szlach{\textbackslash}'\{a\}nyi) of monoidal categories called skew-monoidal categories where the unital and associativity laws are not required to be isomorphisms, only natural transformations. Coherence has to be formulated differently than in the well-known monoidal case. In my (to my knowledge new) version, it becomes a statement of uniqueness of normalizing rewrites. I present a proof of this coherence theorem and also formalize it fully in the dependently typed programming language Agda.},
	urldate = {2020-12-08},
	journal = {Electronic Proceedings in Theoretical Computer Science},
	author = {Uustalu, Tarmo},
	month = jun,
	year = {2014},
	note = {arXiv: 1406.2064
version: 1},
	keywords = {Computer Science - Logic in Computer Science, Computer Science - Programming Languages, F.4.1, Mathematics - Category Theory},
	pages = {68--77},
	annote = {Comment: In Proceedings MSFP 2014, arXiv:1406.1534},
	file = {Uustalu - 2014 - Coherence for Skew-Monoidal Categories.pdf:/Users/wanchengsyuan/Zotero/storage/TU6Z6RM3/Uustalu - 2014 - Coherence for Skew-Monoidal Categories.pdf:application/pdf;arXiv.org Snapshot:/Users/wanchengsyuan/Zotero/storage/JVGVVAZW/1406.html:text/html},
}

@inproceedings{altenkirch_monads_2010,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Monads {Need} {Not} {Be} {Endofunctors}},
	isbn = {978-3-642-12032-9},
	doi = {10.1007/978-3-642-12032-9_21},
	abstract = {We introduce a generalisation of monads, called relative monads, allowing for underlying functors between different categories. Examples include finite-dimensional vector spaces, untyped and typed λ-calculus syntax and indexed containers. We show that the Kleisli and Eilenberg-Moore constructions carry over to relative monads and are related to relative adjunctions. Under reasonable assumptions, relative monads are monoids in the functor category concerned and extend to monads, giving rise to a coreflection between monads and relative monads. Arrows are also an instance of relative monads.},
	language = {en},
	booktitle = {Foundations of {Software} {Science} and {Computational} {Structures}},
	publisher = {Springer},
	author = {Altenkirch, Thorsten and Chapman, James and Uustalu, Tarmo},
	editor = {Ong, Luke},
	year = {2010},
	keywords = {Left Adjoint, Initial Algebra, Monoidal Category, Monoidal Structure, Substitution Rule},
	pages = {297--311},
	file = {Altenkirch et al. - 2010 - Monads Need Not Be Endofunctors.pdf:/Users/wanchengsyuan/Zotero/storage/8T4QKBPP/Altenkirch et al. - 2010 - Monads Need Not Be Endofunctors.pdf:application/pdf},
}

@article{beke_categorification_2011,
	title = {Categorification, term rewriting and the {Knuth}–{Bendix} procedure},
	volume = {215},
	issn = {0022-4049},
	url = {http://www.sciencedirect.com/science/article/pii/S0022404910001325},
	doi = {10.1016/j.jpaa.2010.06.019},
	abstract = {An axiomatization of a finitary, equational universal algebra by a convergent term rewrite system gives rise to a finite, coherent categorification of the algebra.},
	language = {en},
	number = {5},
	urldate = {2020-12-09},
	journal = {Journal of Pure and Applied Algebra},
	author = {Beke, Tibor},
	month = may,
	year = {2011},
	pages = {728--740},
	file = {Beke - 2011 - Categorification, term rewriting and the Knuth–Ben.pdf:/Users/wanchengsyuan/Zotero/storage/SMNJTKG7/Beke - 2011 - Categorification, term rewriting and the Knuth–Ben.pdf:application/pdf;ScienceDirect Snapshot:/Users/wanchengsyuan/Zotero/storage/AZRFTZE2/S0022404910001325.html:text/html},
}

@article{uustalu_eilenberg-kelly_2020,
	series = {The 36th {Mathematical} {Foundations} of {Programming} {Semantics} {Conference}, 2020},
	title = {Eilenberg-{Kelly} {Reloaded}},
	volume = {352},
	issn = {1571-0661},
	url = {http://www.sciencedirect.com/science/article/pii/S1571066120300633},
	doi = {10.1016/j.entcs.2020.09.012},
	abstract = {The Eilenberg-Kelly theorem states that a category C with an object I and two functors ⊗:C×C→C and ⊸:Cop×C→C related by an adjunction −⊗B⊣B⊸− natural in B is monoidal iff it is closed and moreover the adjunction holds internally. We dissect the proof of this theorem and observe that the necessity for a side condition on closedness arises because the standard definition of closed category is left-skew in regards to associativity. We analyze Street's observation that left-skew monoidality is equivalent to left-skew closedness and establish that monoidality is equivalent to closedness unconditionally under an adjusted definition of closedness that requires normal associativity. We also work out a definition of right-skew closedness equivalent to right-skew monoidality. We give examples of each type of structure; in particular, we look at the Kleisli category of a left-strong monad on a left-skew closed category and the Kleisli category of a lax closed monad on a right-skew closed category. We also view skew and normal monoidal and closed categories as special cases of skew and normal promonoidal categories and take a brief look at left-skew prounital-closed categories.},
	language = {en},
	urldate = {2020-12-24},
	journal = {Electronic Notes in Theoretical Computer Science},
	author = {Uustalu, Tarmo and Veltri, Niccolò and Zeilberger, Noam},
	month = oct,
	year = {2020},
	keywords = {closed, Eilenberg-Kelly theorem, Kleisli construction, monoidal closed and bi-closed categories, promonoidal categories, skew and normal monoidal},
	pages = {233--256},
	file = {Uustalu et al. - 2020 - Eilenberg-Kelly Reloaded.pdf:/Users/wanchengsyuan/Zotero/storage/AKHMNT6B/Uustalu et al. - 2020 - Eilenberg-Kelly Reloaded.pdf:application/pdf;ScienceDirect Snapshot:/Users/wanchengsyuan/Zotero/storage/F5R3KS9T/S1571066120300633.html:text/html},
}

@article{uustalu_deductive_nodate,
	title = {Deductive {Systems} and {Coherence} for {Skew} {Prounital} {Closed} {Categories}},
	language = {en},
	author = {Uustalu, Tarmo and Veltri, Niccolo and Zeilberger, Noam},
	pages = {19},
	file = {Uustalu 等。 - Deductive Systems and Coherence for Skew Prounital.pdf:/Users/wanchengsyuan/Zotero/storage/Y4RDQCCA/Uustalu 等。 - Deductive Systems and Coherence for Skew Prounital.pdf:application/pdf},
}

@article{uustalu_deductive_nodate-1,
	title = {Deductive {Systems} and {Coherence} for {Skew} {Prounital} {Closed} {Categories}},
	volume = {332},
	url = {https://cgi.cse.unsw.edu.au/~eptcs/paper.cgi?LFMTP2020:17},
	urldate = {2020-12-24},
	journal = {EPTCS},
	author = {Uustalu, Tarmo and Veltri, Niccolò and Zeilberger, Noam},
	pages = {35--53},
	file = {Uustalu et al. - Deductive Systems and Coherence for Skew Prounital.pdf:/Users/wanchengsyuan/Zotero/storage/X5E9XJD8/Uustalu et al. - Deductive Systems and Coherence for Skew Prounital.pdf:application/pdf;Snapshot:/Users/wanchengsyuan/Zotero/storage/9KYPPGSQ/paper.html:text/html},
}

@article{uustalu_proof_nodate,
	title = {Proof {Theory} of {Partially} {Normal} {Skew} {Monoidal} {Categories}},
	volume = {333},
	url = {https://cgi.cse.unsw.edu.au/~eptcs/paper.cgi?ACT2020:60},
	urldate = {2020-12-24},
	journal = {EPTCS},
	author = {Uustalu, Tarmo and Veltri, Niccolò and Zeilberger, Noam},
	pages = {230--246},
	file = {Uustalu et al. - Proof Theory of Partially Normal Skew Monoidal Cat.pdf:/Users/wanchengsyuan/Zotero/storage/BC4BL4NP/Uustalu et al. - Proof Theory of Partially Normal Skew Monoidal Cat.pdf:application/pdf;Snapshot:/Users/wanchengsyuan/Zotero/storage/UVW2FYNM/paper.html:text/html},
}

@inproceedings{eilenberg_closed_1966,
	address = {Berlin, Heidelberg},
	title = {Closed {Categories}},
	isbn = {978-3-642-99902-4},
	doi = {10.1007/978-3-642-99902-4_22},
	abstract = {In the usual theory of categories, with any two objects A, B of a category A there is associated a set A (A B) of morphisms of A into B. Frequently the set A (A B) is endowed with an additional structure such as a privileged element or an abelian group structure. It has become clear that as the ramifications of the theory of categories increase, the structures that A (A B) will carry will be richer and more complex. The need for a general theory has been widely felt for some time, and beginnings have been made in various directions and often under restrictive hypotheses; e.g. by Mac Lane [15], Kelly [10], Bénabou [3], Linton [12]},
	language = {en},
	booktitle = {Proceedings of the {Conference} on {Categorical} {Algebra}},
	publisher = {Springer},
	author = {Eilenberg, Samuel and Kelly, G. Max},
	editor = {Eilenberg, S. and Harrison, D. K. and MacLane, S. and Röhrl, H.},
	year = {1966},
	keywords = {Monoidal Category, Monoidal Structure, Follow Diagram Commute, Natural Isomorphism, Natural Transformation},
	pages = {421--562},
	file = {Eilenberg and Kelly - 1966 - Closed Categories.pdf:/Users/wanchengsyuan/Zotero/storage/PMSS6J3A/Eilenberg and Kelly - 1966 - Closed Categories.pdf:application/pdf},
}

@inproceedings{guenot_symmetric_2014,
	address = {Vienna Austria},
	title = {Symmetric normalisation for intuitionistic logic},
	isbn = {978-1-4503-2886-9},
	url = {https://dl.acm.org/doi/10.1145/2603088.2603160},
	doi = {10.1145/2603088.2603160},
	abstract = {We present two proof systems for implication-only intuitionistic logic in the calculus of structures. The ﬁrst is a direct adaptation of the standard sequent calculus to the deep inference setting, and we describe a procedure for cut elimination, similar to the one from the sequent calculus, but using a non-local rewriting. The second system is the symmetric completion of the ﬁrst, as normally given in deep inference for logics with a DeMorgan duality: all inference rules have duals, as cut is dual to the identity axiom. We prove a generalisation of cut elimination, that we call symmetric normalisation, where all rules dual to standard ones are permuted up in the derivation. The result is a decomposition theorem having cut elimination and interpolation as corollaries.},
	language = {en},
	urldate = {2021-01-31},
	booktitle = {Proceedings of the {Joint} {Meeting} of the {Twenty}-{Third} {EACSL} {Annual} {Conference} on {Computer} {Science} {Logic} ({CSL}) and the {Twenty}-{Ninth} {Annual} {ACM}/{IEEE} {Symposium} on {Logic} in {Computer} {Science} ({LICS})},
	publisher = {ACM},
	author = {Guenot, Nicolas and Straßburger, Lutz},
	month = jul,
	year = {2014},
	pages = {1--10},
	file = {Guenot and Straßburger - 2014 - Symmetric normalisation for intuitionistic logic.pdf:/Users/wanchengsyuan/Zotero/storage/AEWMRFYT/Guenot and Straßburger - 2014 - Symmetric normalisation for intuitionistic logic.pdf:application/pdf},
}

@article{tiu_local_nodate,
	title = {A {Local} {System} for {Intuitionistic} {Logic}},
	abstract = {This paper presents systems for ﬁrst-order intuitionistic logic and several of its extensions in which all the propositional rules are local, in the sense that, in applying the rules of the system, one needs only a ﬁxed amount of information about the logical expressions involved. The main source of non-locality is the contraction rules. We show that the contraction rules can be restricted to the atomic ones, provided we employ deep-inference, i.e., to allow rules to apply anywhere inside logical expressions. We further show that the use of deep inference allows for modular extensions of intuitionistic logic to Dummett’s intermediate logic LC, G¨odel logic and classical logic. We present the systems in the calculus of structures, a proof theoretic formalism which supports deep-inference. Cut elimination for these systems are proved indirectly by simulating the cut-free sequent systems, or the hypersequent systems in the cases of Dummett’s LC and G¨odel logic, in the cut free systems in the calculus of structures.},
	language = {en},
	author = {Tiu, Alwen},
	pages = {15},
	file = {Tiu - A Local System for Intuitionistic Logic.pdf:/Users/wanchengsyuan/Zotero/storage/3YW9Y7E9/Tiu - A Local System for Intuitionistic Logic.pdf:application/pdf},
}

@incollection{cervesato_algorithmic_2008,
	address = {Berlin, Heidelberg},
	title = {An {Algorithmic} {Interpretation} of a {Deep} {Inference} {System}},
	volume = {5330},
	isbn = {978-3-540-89438-4 978-3-540-89439-1},
	url = {http://link.springer.com/10.1007/978-3-540-89439-1_34},
	abstract = {We set out to ﬁnd something that corresponds to deep inference in the same way that the lambda-calculus corresponds to natural deduction. Starting from natural deduction for the conjunction-implication fragment of intuitionistic logic we design a corresponding deep inference system together with reduction rules on proofs that allow a ﬁne-grained simulation of beta-reduction.},
	language = {en},
	urldate = {2021-01-31},
	booktitle = {Logic for {Programming}, {Artificial} {Intelligence}, and {Reasoning}},
	publisher = {Springer Berlin Heidelberg},
	author = {Brünnler, Kai and McKinley, Richard},
	editor = {Cervesato, Iliano and Veith, Helmut and Voronkov, Andrei},
	year = {2008},
	doi = {10.1007/978-3-540-89439-1_34},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {482--496},
	file = {Brünnler and McKinley - 2008 - An Algorithmic Interpretation of a Deep Inference .pdf:/Users/wanchengsyuan/Zotero/storage/PL9VZRIK/Brünnler and McKinley - 2008 - An Algorithmic Interpretation of a Deep Inference .pdf:application/pdf},
}

@inproceedings{gundersen_atomic_2013,
	address = {New Orleans, LA, USA},
	title = {Atomic {Lambda} {Calculus}: {A} {Typed} {Lambda}-{Calculus} with {Explicit} {Sharing}},
	isbn = {978-1-4799-0413-6},
	shorttitle = {Atomic {Lambda} {Calculus}},
	url = {http://ieeexplore.ieee.org/document/6571563/},
	doi = {10.1109/LICS.2013.37},
	abstract = {An explicit–sharing lambda-calculus is presented, based on a Curry–Howard-style interpretation of the deep inference proof formalism. Duplication of subterms during reduction proceeds ‘atomically’, i.e. on individual constructors, similar to optimal graph reduction in the style of Lamping. The calculus preserves strong normalisation with respect to the lambdacalculus, and achieves fully lazy sharing.},
	language = {en},
	urldate = {2021-01-31},
	booktitle = {2013 28th {Annual} {ACM}/{IEEE} {Symposium} on {Logic} in {Computer} {Science}},
	publisher = {IEEE},
	author = {Gundersen, Tom and Heijltjes, Willem and Parigot, Michel},
	month = jun,
	year = {2013},
	pages = {311--320},
	file = {Gundersen et al. - 2013 - Atomic Lambda Calculus A Typed Lambda-Calculus wi.pdf:/Users/wanchengsyuan/Zotero/storage/B6SYHNRK/Gundersen et al. - 2013 - Atomic Lambda Calculus A Typed Lambda-Calculus wi.pdf:application/pdf},
}

@article{guiraud_three_2006,
	title = {The three dimensions of proofs},
	volume = {141},
	issn = {0168-0072},
	url = {https://www.sciencedirect.com/science/article/pii/S0168007205001892},
	doi = {10.1016/j.apal.2005.12.012},
	abstract = {In this document, we study a 3-polygraphic translation for the proofs of SKS, a formal system for classical propositional logic. We prove that the free 3-category generated by this 3-polygraph describes the proofs of classical propositional logic modulo structural bureaucracy. We give a three-dimensional generalization of Penrose diagrams and use it to provide several pictures of a proof. We sketch how local transformations of proofs yield a non contrived example of four-dimensional rewriting.},
	language = {en},
	number = {1},
	urldate = {2021-02-09},
	journal = {Annals of Pure and Applied Logic},
	author = {Guiraud, Yves},
	month = aug,
	year = {2006},
	keywords = {Classical propositional logic, Polygraph, Proof theory, Structural bureaucracy, Three-dimensional proof},
	pages = {266--295},
	file = {Guiraud - 2006 - The three dimensions of proofs.pdf:/Users/wanchengsyuan/Zotero/storage/CZBAXCB9/Guiraud - 2006 - The three dimensions of proofs.pdf:application/pdf;ScienceDirect Snapshot:/Users/wanchengsyuan/Zotero/storage/AMB32G6W/S0168007205001892.html:text/html},
}

@article{r_buss_undecidability_1991,
	title = {The undecidability of k-provability},
	volume = {53},
	issn = {01680072},
	url = {https://linkinghub.elsevier.com/retrieve/pii/016800729190059U},
	doi = {10.1016/0168-0072(91)90059-U},
	language = {en},
	number = {1},
	urldate = {2021-02-24},
	journal = {Annals of Pure and Applied Logic},
	author = {R. Buss, Samuel},
	month = jul,
	year = {1991},
	pages = {75--102},
	file = {R. Buss - 1991 - The undecidability of k-provability.pdf:/Users/wanchengsyuan/Zotero/storage/I44IJR3X/R. Buss - 1991 - The undecidability of k-provability.pdf:application/pdf},
}

@article{guenot_focused_2010,
	title = {Focused {Proof} {Search} for {Linear} {Logic} in the {Calculus} of {Structures}},
	url = {http://drops.dagstuhl.de/opus/volltexte/2010/2586/},
	doi = {10.4230/LIPICS.ICLP.2010.84},
	abstract = {The proof-theoretic approach to logic programming has beneﬁted from the introduction of focused proof systems, through the non-determinism reduction and control they provide when searching for proofs in the sequent calculus. However, this technique was not available in the calculus of structures, known for inducing even more non-determinism than other logical formalisms. This work in progress aims at translating the notion of focusing into the presentation of linear logic in this setting, and use some of its speciﬁc features, such as deep application of rules and ﬁne granularity, in order to improve proof search procedures. The starting point for this research line is the multiplicative fragment of linear logic, for which a simple focused proof system can be built.},
	language = {en},
	urldate = {2021-02-26},
	author = {Guenot, Nicolas},
	collaborator = {Herbstritt, Marc},
	year = {2010},
	note = {Artwork Size: 10 pages
Medium: application/pdf
Publisher: Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik GmbH, Wadern/Saarbruecken, Germany},
	keywords = {000 Computer science, knowledge, general works, Computer Science},
	pages = {10 pages},
	annote = {Other
The proof-theoretic approach to logic programming has benefited from the introduction of focused proof systems, through the non-determinism reduction and control they provide when searching for proofs in the sequent calculus. However, this technique was not available in the calculus of structures, known for inducing even more non-determinism than other logical formalisms. This work in progress aims at translating the notion of focusing into the presentation of linear logic in this setting, and use some of its specific features, such as deep application of rules and fine granularity, in order to improve proof search procedures. The starting point for this research line is the multiplicative fragment of linear logic, for which a simple focused proof system can be built.},
	file = {Guenot - 2010 - Focused Proof Search for Linear Logic in the Calcu.pdf:/Users/wanchengsyuan/Zotero/storage/IVG64GCX/Guenot - 2010 - Focused Proof Search for Linear Logic in the Calcu.pdf:application/pdf},
}

@article{noauthor_institut_1992,
	title = {Institut national de recherche en informatique et en automatique},
	volume = {37},
	issn = {0759-1063, 2070-2779},
	url = {http://journals.sagepub.com/doi/10.1177/075910639203700105},
	doi = {10.1177/075910639203700105},
	abstract = {These are the notes for a 5-lecture-course given at ESSLLI 2006 in Malaga, Spain. The URL of the school is http://esslli2006.lcc.uma.es/. This version slightly diﬀers from the one which has been distributed at the school because typos have been removed and comments and suggestions by students have been worked in.},
	language = {en},
	number = {1},
	urldate = {2021-02-26},
	journal = {Bulletin of Sociological Methodology/Bulletin de Méthodologie Sociologique},
	month = dec,
	year = {1992},
	pages = {55--57},
	file = {1992 - Institut national de recherche en informatique et .pdf:/Users/wanchengsyuan/Zotero/storage/LFEIJDZT/1992 - Institut national de recherche en informatique et .pdf:application/pdf},
}

@article{strasburger_deep_nodate,
	title = {From {Deep} {Inference} to {Proof} {Nets} via {Cut} {Elimination}},
	abstract = {This paper shows how derivations in the deep inference system SKS for classical propositional logic can be translated into proof nets. Since an SKS derivation contains more information about a proof than the corresponding proof net, we observe a loss of information which can be understood as “eliminating bureaucracy”. Technically this is achieved by cut reduction on proof nets. As an intermediate step between the two extremes, SKS derivations and proof nets, we will see proof graphs representing derivations in “Formalism A”.},
	language = {en},
	author = {Straßburger, Lutz},
	pages = {41},
	file = {Straßburger - From Deep Inference to Proof Nets via Cut Eliminat.pdf:/Users/wanchengsyuan/Zotero/storage/AI6TEGV9/Straßburger - From Deep Inference to Proof Nets via Cut Eliminat.pdf:application/pdf},
}

@inproceedings{acclavio_logic_2020,
	address = {Saarbrücken Germany},
	title = {Logic {Beyond} {Formulas}: {A} {Proof} {System} on {Graphs}},
	isbn = {978-1-4503-7104-9},
	shorttitle = {Logic {Beyond} {Formulas}},
	url = {https://dl.acm.org/doi/10.1145/3373718.3394763},
	doi = {10.1145/3373718.3394763},
	abstract = {In this paper we present a proof system that operates on graphs instead of formulas. We begin our quest with the well-known correspondence between formulas and cographs, which are undirected graphs that do not have P4 (the fourvertex path) as vertex-induced subgraph; and then we drop that condition and look at arbitrary (undirected) graphs. The consequence is that we lose the tree structure of the formulas corresponding to the cographs. Therefore we cannot use standard proof theoretical methods that depend on that tree structure. In order to overcome this difficulty, we use a modular decomposition of graphs and some techniques from deep inference where inference rules do not rely on the main connective of a formula. For our proof system we show the admissibility of cut and a generalization of the splitting property. Finally, we show that our system is a conservative extension of multiplicative linear logic (MLL) with mix, meaning that if a graph is a cograph and provable in our system, then it is also provable in MLL+mix.},
	language = {en},
	urldate = {2021-02-26},
	booktitle = {Proceedings of the 35th {Annual} {ACM}/{IEEE} {Symposium} on {Logic} in {Computer} {Science}},
	publisher = {ACM},
	author = {Acclavio, Matteo and Horne, Ross and Straßburger, Lutz},
	month = jul,
	year = {2020},
	pages = {38--52},
	file = {Acclavio et al. - 2020 - Logic Beyond Formulas A Proof System on Graphs.pdf:/Users/wanchengsyuan/Zotero/storage/DZH3VQ9P/Acclavio et al. - 2020 - Logic Beyond Formulas A Proof System on Graphs.pdf:application/pdf},
}

@article{chaudhuri_focused_2011,
	title = {The {Focused} {Calculus} of {Structures}},
	url = {http://drops.dagstuhl.de/opus/volltexte/2011/3229/},
	doi = {10.4230/LIPICS.CSL.2011.159},
	abstract = {The focusing theorem identiﬁes a complete class of sequent proofs that have no inessential nondeterministic choices and restrict the essential choices to a particular normal form. Focused proofs are therefore well suited both for the search and for the representation of sequent proofs. The calculus of structures is a proof formalism that allows rules to be applied deep inside a formula. Through this freedom it can be used to give analytic proof systems for a wider variety of logics than the sequent calculus, but standard presentations of this calculus are too permissive, allowing too many proofs. In order to make it more amenable to proof search, we transplant the focusing theorem from the sequent calculus to the calculus of structures. The key technical contribution is an incremental treatment of focusing that avoids trivializing the calculus of structures. We give a direct inductive proof of the completeness of the focused calculus of structures with respect to a more standard unfocused form. We also show that any focused sequent proof can be represented in the focused calculus of structures, and, conversely, any proof in the focused calculus of structures corresponds to a focused sequent proof.},
	language = {en},
	urldate = {2021-03-01},
	author = {Chaudhuri, Kaustuv and Guenot, Nicolas and Straßburger, Lutz},
	collaborator = {Herbstritt, Marc},
	year = {2011},
	note = {Artwork Size: 15 pages
Medium: application/pdf
Publisher: Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik GmbH, Wadern/Saarbruecken, Germany},
	keywords = {000 Computer science, knowledge, general works, Computer Science},
	pages = {15 pages},
	annote = {Other
The focusing theorem identifies a complete class of sequent proofs that have no inessential non-deterministic choices and restrict the essential choices to a particular normal form. Focused proofs are therefore well suited both for the search and for the representation of sequent proofs. The calculus of structures is a proof formalism that allows rules to be applied deep inside a formula. Through this freedom it can be used to give analytic proof systems for a wider variety of logics than the sequent calculus, but standard presentations of this calculus are too permissive, allowing too many proofs. In order to make it more amenable to proof search, we transplant the focusing theorem from the sequent calculus to the calculus of structures. The key technical contribution is an incremental treatment of focusing that avoids trivializing the calculus of structures. We give a direct inductive proof of the completeness of the focused calculus of structures with respect to a more standard unfocused form. We also show that any focused sequent proof can be represented in the focused calculus of structures, and, conversely, any proof in the focused calculus of structures corresponds to a focused sequent proof.},
	file = {Chaudhuri et al. - 2011 - The Focused Calculus of Structures.pdf:/Users/wanchengsyuan/Zotero/storage/A3AFG36R/Chaudhuri et al. - 2011 - The Focused Calculus of Structures.pdf:application/pdf},
}

@inproceedings{wang_temporalizing_2013,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Temporalizing {Modal} {Epistemic} {Logic}},
	isbn = {978-3-642-35722-0},
	doi = {10.1007/978-3-642-35722-0_26},
	abstract = {Timed Modal Epistemic Logic, tMEL, is a newly introduced logical framework for reasoning about the modeled agent’s knowledge. The framework, derived from the study of Justification Logic, is adapted from the traditional Modal Epistemic Logic, MEL, to serve as a logically non-omniscient epistemic logic and dealing with problems where the temporal constraint is an unavoidable factor. In this paper we will give a semantic proof for the formal connection between MEL and tMEL, the Temporalization Theorem, which states that every MEL theorem can be turned into a tMEL theorem if suitable time labels can be found for each knowledge statement involved in the MEL theorem. As a result, the proof also gives us a better understanding of the semantics on the both sides of the theorem.},
	language = {en},
	booktitle = {Logical {Foundations} of {Computer} {Science}},
	publisher = {Springer},
	author = {Wang, Ren-June},
	editor = {Artemov, Sergei and Nerode, Anil},
	year = {2013},
	keywords = {Agent Theory, Epistemic Logic, Justification Logic, Modal Logic, Realization Theoremn, Reasoning Time, Temporalization Theorem, Timed Modal Epistemic Logic},
	pages = {359--371},
	file = {Wang - 2013 - Temporalizing Modal Epistemic Logic.pdf:/Users/wanchengsyuan/Zotero/storage/LIPH9RBU/Wang - 2013 - Temporalizing Modal Epistemic Logic.pdf:application/pdf},
}

@inproceedings{capretta_coalgebraic_2016,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Coalgebraic} {View} of {Bar} {Recursion} and {Bar} {Induction}},
	isbn = {978-3-662-49630-5},
	doi = {10.1007/978-3-662-49630-5_6},
	abstract = {We reformulate the bar recursion and induction principles in terms of recursive and wellfounded coalgebras. Bar induction was originally proposed by Brouwer as an axiom to recover certain classically valid theorems in a constructive setting. It is a form of induction on non-wellfounded trees satisfying certain properties. Bar recursion, introduced later by Spector, is the corresponding function definition principle.We give a generalization of these principles, by introducing the notion of barred coalgebra: a process with a branching behaviour given by a functor, such that all possible computations terminate.Coalgebraic bar recursion is the statement that every barred coalgebra is recursive; a recursive coalgebra is one that allows definition of functions by a coalgebra-to-algebra morphism. It is a framework to characterize valid forms of recursion for terminating functional programs. One application of the principle is the tabulation of continuous functions: Ghani, Hancock and Pattinson defined a type of wellfounded trees that represent continuous functions on streams. Bar recursion allows us to prove that every stably continuous function can be tabulated to such a tree, where by stability we mean that the modulus of continuity is its own modulus. Coalgebraic bar induction states that every barred coalgebra is wellfounded; a wellfounded coalgebra is one that admits proof by induction.},
	language = {en},
	booktitle = {Foundations of {Software} {Science} and {Computation} {Structures}},
	publisher = {Springer},
	author = {Capretta, Venanzio and Uustalu, Tarmo},
	editor = {Jacobs, Bart and Löding, Christof},
	year = {2016},
	keywords = {Initial Algebra, Constructive Setting, Continuity Principle, Finite Path, Polynomial Functor},
	pages = {91--106},
	file = {Capretta and Uustalu - 2016 - A Coalgebraic View of Bar Recursion and Bar Induct.pdf:/Users/wanchengsyuan/Zotero/storage/5VDHB6CN/Capretta and Uustalu - 2016 - A Coalgebraic View of Bar Recursion and Bar Induct.pdf:application/pdf},
}

@article{prawitz_seeming_2019,
	title = {The {Seeming} {Interdependence} {Between} the {Concepts} of {Valid} {Inference} and {Proof}},
	volume = {38},
	issn = {1572-8749},
	url = {https://doi.org/10.1007/s11245-017-9506-4},
	doi = {10.1007/s11245-017-9506-4},
	abstract = {We may try to explain proofs as chains of valid inference, but the concept of validity needed in such an explanation cannot be the traditional one. For an inference to be legitimate in a proof it must have sufficient epistemic power, so that the proof really justifies its final conclusion. However, the epistemic concepts used to account for this power are in their turn usually explained in terms of the concept of proof. To get out of this circle we may consider an idea within intuitionism about what it is to justify the assertion of a proposition. It depends on Heyting’s view of the meaning of a proposition, but does not presuppose the concept of inference or of proof as chains of inferences. I discuss this idea and what is required in order to use it for an adequate notion of valid inference.},
	language = {en},
	number = {3},
	urldate = {2021-03-15},
	journal = {Topoi},
	author = {Prawitz, Dag},
	month = sep,
	year = {2019},
	pages = {493--503},
	file = {Prawitz - 2019 - The Seeming Interdependence Between the Concepts o.pdf:/Users/wanchengsyuan/Zotero/storage/YHMB9Q4S/Prawitz - 2019 - The Seeming Interdependence Between the Concepts o.pdf:application/pdf},
}

@article{street_skew-closed_2013,
	title = {Skew-closed categories},
	volume = {217},
	issn = {0022-4049},
	url = {https://www.sciencedirect.com/science/article/pii/S0022404912002964},
	doi = {10.1016/j.jpaa.2012.09.020},
	abstract = {Spurred by the new examples found by Kornel Szlachányi of a form of lax monoidal category, the author felt the time ripe to publish a reworking of Eilenberg and Kelly’s original paper on closed categories appropriate to the laxer context. The new examples are connected with bialgebroids. In a separate paper with Stephen Lack, we have also used the concept to give an alternative definition of quantum category and quantum groupoid. Szlachányi has called the lax notion skew monoidal. This paper defines skew-closed category, proves Yoneda lemmas for categories enriched over such, and looks at closed cocompletion.},
	language = {en},
	number = {6},
	urldate = {2021-03-18},
	journal = {Journal of Pure and Applied Algebra},
	author = {Street, Ross},
	month = jun,
	year = {2013},
	pages = {973--988},
	file = {Street - 2013 - Skew-closed categories.pdf:/Users/wanchengsyuan/Zotero/storage/2XY9B2BB/Street - 2013 - Skew-closed categories.pdf:application/pdf;ScienceDirect Snapshot:/Users/wanchengsyuan/Zotero/storage/CDYEFFAY/S0022404912002964.html:text/html},
}

@article{loregian_coend_2020,
	title = {Coend calculus},
	url = {http://arxiv.org/abs/1501.02503},
	abstract = {The book formerly known as "This is the (co)end, my only (co)friend".},
	urldate = {2021-04-09},
	journal = {arXiv:1501.02503 [math]},
	author = {Loregian, Fosco},
	month = dec,
	year = {2020},
	note = {arXiv: 1501.02503},
	keywords = {Mathematics - Category Theory},
	annote = {Comment: This is the final version a moment before book printing; slightly slimmer version, lots of mistakes removed},
	file = {Loregian - 2020 - Coend calculus.pdf:/Users/wanchengsyuan/Zotero/storage/I4B3DTG4/Loregian - 2020 - Coend calculus.pdf:application/pdf;arXiv.org Snapshot:/Users/wanchengsyuan/Zotero/storage/4CS832N6/1501.html:text/html},
}

@article{kelly_coherence_1971,
	title = {Coherence in closed categories},
	volume = {1},
	issn = {0022-4049},
	url = {https://www.sciencedirect.com/science/article/pii/0022404971900132},
	doi = {10.1016/0022-4049(71)90013-2},
	language = {en},
	number = {1},
	urldate = {2021-05-06},
	journal = {Journal of Pure and Applied Algebra},
	author = {Kelly, G. M. and Maclane, S.},
	month = jan,
	year = {1971},
	pages = {97--140},
	file = {Kelly and Maclane - 1971 - Coherence in closed categories.pdf:/Users/wanchengsyuan/Zotero/storage/GGBLRIC5/Kelly and Maclane - 1971 - Coherence in closed categories.pdf:application/pdf},
}

@article{martini_modal_1994,
	title = {A {Modal} {View} of {Linear} {Logic}},
	volume = {59},
	issn = {0022-4812},
	url = {https://www.jstor.org/stable/2275915},
	doi = {10.2307/2275915},
	abstract = {We present a sequent calculus for the modal logic S4, and building on some relevant features of this system (the absence of contraction rules and the confinement of weakenings into axioms and modal rules) we show how S4 can easily be translated into full propositional linear logic, extending the Grishin-Ono translation of classical logic into linear logic. The translation introduces linear modalities (exponentials) only in correspondence with S4 modalities. We discuss the complexity of the decision problem for several classes of linear formulas naturally arising from the proposed translations.},
	number = {3},
	urldate = {2021-05-06},
	journal = {The Journal of Symbolic Logic},
	author = {Martini, Simone and Masini, Andrea},
	year = {1994},
	note = {Publisher: Association for Symbolic Logic},
	pages = {888--899},
	file = {Martini and Masini - 1994 - A Modal View of Linear Logic.pdf:/Users/wanchengsyuan/Zotero/storage/ZAYEYNME/Martini and Masini - 1994 - A Modal View of Linear Logic.pdf:application/pdf},
}

@article{fukuda_higher-arity_2018,
	title = {A {Higher}-arity {Sequent} {Calculus} for {Model} {Linear} {Logic} ({Proof} theory and proving)},
	issn = {1880-2818},
	url = {https://ci.nii.ac.jp/naid/120006645672/},
	number = {2083},
	urldate = {2021-05-07},
	journal = {RIMS Kôkyûroku},
	author = {Fukuda, Yosuke and Yoshimizu, Akira},
	month = aug,
	year = {2018},
	note = {Publisher: RIMS Kyoto University},
	pages = {76--87},
	file = {Fukuda and Yoshimizu - 2018 - A Higher-arity Sequent Calculus for Model Linear L.pdf:/Users/wanchengsyuan/Zotero/storage/Y6XTQSG7/Fukuda and Yoshimizu - 2018 - A Higher-arity Sequent Calculus for Model Linear L.pdf:application/pdf;A Higher-arity Sequent Calculus for Model Linear Logic (Proof theory and proving) Snapshot:/Users/wanchengsyuan/Zotero/storage/U7BTP3MB/120006645672.html:text/html},
}

@article{pfenning_modal_1995,
	series = {{MFPS} {XI}, {Mathematical} {Foundations} of {Programming} {Semantics}, {Eleventh} {Annual} {Conference}},
	title = {On a {Modal} λ-{Calculus} for {S4}*},
	volume = {1},
	issn = {1571-0661},
	url = {https://www.sciencedirect.com/science/article/pii/S1571066104000283},
	doi = {10.1016/S1571-0661(04)00028-3},
	abstract = {We present λ→□, a concise formulation of a proof term calculus for the intuitionistic modal logic S4 that is well-suited for practical applications. We show that, with respect to provability, it is equivalent to other formulations in the literature, sketch a simple type checking algorithm, and prove subject reduction and the existence of canonical forms for well-typed terms. Applications include a new formulation of natural deduction for intuitionistic linear logic, modal logical frameworks, and a logical analysis of staged computation and binding-time analysis for functional languages [6].},
	language = {en},
	urldate = {2021-05-12},
	journal = {Electronic Notes in Theoretical Computer Science},
	author = {Pfenning, F. and Wong, H. C.},
	month = jan,
	year = {1995},
	pages = {515--534},
	file = {Pfenning and Wong - 1995 - On a Modal λ-Calculus for S4.pdf:/Users/wanchengsyuan/Zotero/storage/7RX3UDNY/Pfenning and Wong - 1995 - On a Modal λ-Calculus for S4.pdf:application/pdf;ScienceDirect Snapshot:/Users/wanchengsyuan/Zotero/storage/X4CQ9VYK/S1571066104000283.html:text/html},
}

@article{bierman_intuitionistic_2000,
	title = {On an {Intuitionistic} {Modal} {Logic}},
	volume = {65},
	issn = {1572-8730},
	url = {https://doi.org/10.1023/A:1005291931660},
	doi = {10.1023/A:1005291931660},
	abstract = {In this paper we consider an intuitionistic variant of the modal logic S4 (which we call IS4). The novelty of this paper is that we place particular importance on the natural deduction formulation of IS4— our formulation has several important metatheoretic properties. In addition, we study models of IS4— not in the framework of Kirpke semantics, but in the more general framework of category theory. This allows not only a more abstract definition of a whole class of models but also a means of modelling proofs as well as provability.},
	language = {en},
	number = {3},
	urldate = {2021-05-13},
	journal = {Studia Logica},
	author = {Bierman, G. M. and de Paiva, V. C. V.},
	month = aug,
	year = {2000},
	pages = {383--416},
	file = {Bierman and de Paiva - 2000 - On an Intuitionistic Modal Logic.pdf:/Users/wanchengsyuan/Zotero/storage/NIRGAVKP/Bierman and de Paiva - 2000 - On an Intuitionistic Modal Logic.pdf:application/pdf},
}

@inproceedings{barenbaum_rewrites_2020,
	address = {New York, NY, USA},
	series = {{PPDP} '20},
	title = {Rewrites as {Terms} through {Justification} {Logic}},
	isbn = {978-1-4503-8821-4},
	url = {https://doi.org/10.1145/3414080.3414091},
	doi = {10.1145/3414080.3414091},
	abstract = {Justification Logic is a refinement of modal logic where the modality is annotated with a reason s for “knowing” A and written . The expression s is a proof of A that may be encoded as a lambda calculus term of type A, according to the propositions-as-types interpretation. Our starting point is the observation that terms of type are reductions between lambda calculus terms. Reductions are usually encoded as rewrites essential tools in analyzing the reduction behavior of lambda calculus and term rewriting systems, such as when studying standardization, needed strategies, Lévy permutation equivalence, etc. We explore a new propositions-as-types interpretation for Justification Logic, based on the principle that terms of type are proof terms encoding reductions (with source s). Note that this provides a logical language to reason about rewrites.},
	urldate = {2021-05-13},
	booktitle = {Proceedings of the 22nd {International} {Symposium} on {Principles} and {Practice} of {Declarative} {Programming}},
	publisher = {Association for Computing Machinery},
	author = {Barenbaum, Pablo and Bonelli, Eduardo},
	month = sep,
	year = {2020},
	keywords = {Curry-Howard, Lambda calculus, modal logic, term rewriting, type systems},
	pages = {1--13},
	file = {Barenbaum and Bonelli - 2020 - Rewrites as Terms through Justification Logic.pdf:/Users/wanchengsyuan/Zotero/storage/QU74HQ6B/Barenbaum and Bonelli - 2020 - Rewrites as Terms through Justification Logic.pdf:application/pdf},
}

@article{lincoln_decision_1992,
	title = {Decision problems for propositional linear logic},
	volume = {56},
	issn = {0168-0072},
	url = {https://www.sciencedirect.com/science/article/pii/016800729290075B},
	doi = {10.1016/0168-0072(92)90075-B},
	abstract = {Linear logic, introduced by Girard, is a refinement of classical logic with a natural, intrinsic accounting of resources. This accounting is made possible by removing the ‘structural’ rules of contraction and weakening, adding a modal operator and adding finer versions of the propositional connectives. Linear logic has fundamental logical interest and applications to computer science, particularly to Petri nets, concurrency, storage allocation, garbage collection and the control structure of logic programs. In addition, there is a direct correspondence between polynomial-time computation and proof normalization in a bounded form of linear logic. In this paper we show that unlike most other propositional (quantifier-free) logics, full propositional linear logic is undecidable. Further, we prove that without the modal storage operator, which indicates unboundedness of resources, the decision problem becomes PSPACE-complete. We also establish membership in NP for the multiplicative fragment, NP-completeness for the multiplicative fragment extended with unrestricted weakening, and undecidability for fragments of noncommutative propositional linear logic.},
	language = {en},
	number = {1},
	urldate = {2021-05-17},
	journal = {Annals of Pure and Applied Logic},
	author = {Lincoln, Patrick and Mitchell, John and Scedrov, Andre and Shankar, Natarajan},
	month = apr,
	year = {1992},
	pages = {239--311},
	file = {Lincoln et al. - 1992 - Decision problems for propositional linear logic.pdf:/Users/wanchengsyuan/Zotero/storage/HQMRDDNJ/Lincoln et al. - 1992 - Decision problems for propositional linear logic.pdf:application/pdf;ScienceDirect Snapshot:/Users/wanchengsyuan/Zotero/storage/36NBT57W/016800729290075B.html:text/html},
}

@incollection{ono_structural_1990,
	address = {Boston, MA},
	title = {Structural {Rules} and a {Logical} {Hierarchy}},
	isbn = {978-1-4613-0609-2},
	url = {https://doi.org/10.1007/978-1-4613-0609-2_8},
	abstract = {Gentzen-type sequent calculi usually contain three structural rules, i.e., exchange, contraction and weakening rules. In recent years, however, there have been various studies on logics that have not included some or any of these structural rules. The motives or purposes of these studies have been so diverse that sometimes close connections between them have been overlooked. Here we will make a brief survey of recent results on these logics in an attempt to make these interrelationships clearer.},
	language = {en},
	urldate = {2021-05-17},
	booktitle = {Mathematical {Logic}},
	publisher = {Springer US},
	author = {Ono, Hiroakira},
	editor = {Petkov, Petio Petrov},
	year = {1990},
	doi = {10.1007/978-1-4613-0609-2_8},
	keywords = {Categorial Grammar, Classical Logic, Deduction System, Intuitionistic Logic, Linear Logic},
	pages = {95--104},
}

@article{mints_linear_1998,
	title = {Linear {Lambda}-{Terms} and {Natural} {Deduction}},
	volume = {60},
	issn = {0039-3215},
	url = {https://www.jstor.org/stable/20015960},
	number = {1},
	urldate = {2021-05-19},
	journal = {Studia Logica: An International Journal for Symbolic Logic},
	author = {Mints, G.},
	year = {1998},
	note = {Publisher: Springer},
	pages = {209--231},
	file = {Mints - 1998 - Linear Lambda-Terms and Natural Deduction.pdf:/Users/wanchengsyuan/Google 雲端硬碟/TalTech/Mints - 1998 - Linear Lambda-Terms and Natural Deduction.pdf:application/pdf},
}

@inproceedings{chaudhuri_focusing_2005,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Focusing the {Inverse} {Method} for {Linear} {Logic}},
	isbn = {978-3-540-31897-2},
	doi = {10.1007/11538363_15},
	abstract = {Focusing is traditionally seen as a means of reducing inessential non-determinism in backward-reasoning strategies such as uniform proof-search or tableaux systems. In this paper we construct a form of focused derivations for propositional linear logic that is appropriate for forward reasoning in the inverse method. We show that the focused inverse method conservatively generalizes the classical hyperresolution strategy for Horn-theories, and demonstrate through a practical implementation that the focused inverse method is considerably faster than the non-focused version.},
	language = {en},
	booktitle = {Computer {Science} {Logic}},
	publisher = {Springer},
	author = {Chaudhuri, Kaustuv and Pfenning, Frank},
	editor = {Ong, Luke},
	year = {2005},
	keywords = {Intuitionistic Logic, Linear Logic, Horn Clause, Inverse Method, Sequent Calculus},
	pages = {200--215},
	file = {Chaudhuri and Pfenning - 2005 - Focusing the Inverse Method for Linear Logic.pdf:/Users/wanchengsyuan/Zotero/storage/N8N5J9LJ/Chaudhuri and Pfenning - 2005 - Focusing the Inverse Method for Linear Logic.pdf:application/pdf},
}

@article{bourke_skew_2018,
	title = {Skew monoidal categories and skew multicategories},
	volume = {506},
	issn = {0021-8693},
	url = {https://www.sciencedirect.com/science/article/pii/S0021869318301996},
	doi = {10.1016/j.jalgebra.2018.02.039},
	abstract = {We describe a perfect correspondence between skew monoidal categories and certain generalised multicategories, called skew multicategories, that arise in nature.},
	language = {en},
	urldate = {2021-06-16},
	journal = {Journal of Algebra},
	author = {Bourke, John and Lack, Stephen},
	month = jul,
	year = {2018},
	keywords = {Multicategory, Operad, Skew monoidal category},
	pages = {237--266},
	file = {Submitted Version:/Users/wanchengsyuan/Zotero/storage/W7A574L6/Bourke and Lack - 2018 - Skew monoidal categories and skew multicategories.pdf:application/pdf;ScienceDirect Snapshot:/Users/wanchengsyuan/Zotero/storage/AEJRMZFB/S0021869318301996.html:text/html},
}

@article{moggi_notions_1991,
	series = {Selections from 1989 {IEEE} {Symposium} on {Logic} in {Computer} {Science}},
	title = {Notions of computation and monads},
	volume = {93},
	issn = {0890-5401},
	url = {https://www.sciencedirect.com/science/article/pii/0890540191900524},
	doi = {10.1016/0890-5401(91)90052-4},
	abstract = {The λ-calculus is considered a useful mathematical tool in the study of programming languages, since programs can be identified with λ-terms. However, if one goes further and uses βη-conversion to prove equivalence of programs, then a gross simplification is introduced (programs are identified with total functions from values to values) that may jeopardise the applicability of theoretical results. In this paper we introduce calculi, based on a categorical semantics for computations, that provide a correct basis for proving equivalence of programs for a wide range of notions of computation.},
	language = {en},
	number = {1},
	urldate = {2021-06-16},
	journal = {Information and Computation},
	author = {Moggi, Eugenio},
	month = jul,
	year = {1991},
	pages = {55--92},
	file = {Moggi - 1991 - Notions of computation and monads.pdf:/Users/wanchengsyuan/Zotero/storage/7F3GBDWN/Moggi - 1991 - Notions of computation and monads.pdf:application/pdf;ScienceDirect Snapshot:/Users/wanchengsyuan/Zotero/storage/JET3XAJX/0890540191900524.html:text/html},
}

@inproceedings{moggi_computational_1989,
	title = {Computational lambda-calculus and monads},
	doi = {10.1109/LICS.1989.39155},
	abstract = {The lambda -calculus is considered a useful mathematical tool in the study of programming languages. However, if one uses beta eta -conversion to prove equivalence of programs, then a gross simplification is introduced. The author gives a calculus based on a categorical semantics for computations, which provides a correct basis for proving equivalence of programs, independent from any specific computational model.{\textless}{\textgreater}},
	booktitle = {[1989] {Proceedings}. {Fourth} {Annual} {Symposium} on {Logic} in {Computer} {Science}},
	author = {Moggi, E.},
	month = jun,
	year = {1989},
	keywords = {Calculus, Computer languages, Computer science, Contracts, Logic programming, Mathematical model, Mathematical programming, Reasoning about programs},
	pages = {14--23},
	file = {Moggi - 1989 - Computational lambda-calculus and monads.html:/Users/wanchengsyuan/Zotero/storage/PNC3927G/Moggi - 1989 - Computational lambda-calculus and monads.html:text/html},
}

@misc{noauthor_proofs_nodate,
	title = {Proofs without syntax {\textbar} {Annals} of {Mathematics}},
	url = {https://annals.math.princeton.edu/2006/164-3/p09},
	language = {en-US},
	urldate = {2021-06-16},
	file = {Proofs without syntax  Annals of Mathematics.html:/Users/wanchengsyuan/Zotero/storage/GYZP6ZQC/Proofs without syntax  Annals of Mathematics.html:text/html},
}

@article{deyoung_reasoning_2008,
	title = {Reasoning about the {Consequences} of {Authorization} {Policies} in a {Linear} {Epistemic} {Logic}},
	url = {/articles/journal_contribution/Reasoning_about_the_Consequences_of_Authorization_Policies_in_a_Linear_Epistemic_Logic/6608834/1},
	doi = {10.1184/R1/6608834.v1},
	abstract = {Authorization policies are not stand-alone objects: they are used to selectively permit actions that change the state of a system. Thus, it is desirable to have a framework for reasoning about the semantic consequences of policies. To this end, we extend a rewriting interpretation of linear logic with connectives for modeling affirmation, knowledge, and possession. To cleanly confine semantic effects to the rewrite sequence, we introduce a monad. The result is a richly expressive logic that elegantly integrates policies and their effects. After presenting this logic and its metatheory, we demonstrate its utility by proving properties that relate a simple file system’s policies to their semantic consequences},
	language = {en},
	urldate = {2021-06-17},
	author = {DeYoung, Henry and Pfenning, Frank},
	month = jan,
	year = {2008},
	note = {Publisher: Carnegie Mellon University},
	file = {Snapshot:/Users/wanchengsyuan/Zotero/storage/Q3V5PD3N/6608834.html:text/html;Full Text PDF:/Users/wanchengsyuan/Zotero/storage/XLEUKV4S/DeYoung and Pfenning - 2008 - Reasoning about the Consequences of Authorization .pdf:application/pdf},
}

@article{kamide_linear_2006,
	title = {Linear and affine logics with temporal, spatial and epistemic operators},
	volume = {353},
	issn = {0304-3975},
	url = {https://www.sciencedirect.com/science/article/pii/S0304397505007863},
	doi = {10.1016/j.tcs.2005.10.043},
	abstract = {A temporal spatial epistemic intuitionistic linear logic (TSEILL) is introduced, and the completeness theorem for this logic is proved with respect to Kripke semantics. TSEILL has three temporal modal operators: [F] (any time in the future), [N] (next time) and [P] (past), some spatial modal operators [li] (locations), two epistemic modal operators; [K] (know) and 〈K〉, and a linear modal operator ! (exponential). A basic normal modal intuitionistic affine logic (BIAL) and its normal extensions are also defined, and the completeness theorems for these logics are proved with respect to Kripke semantics. In the proposed semantic framework of these normal extensions, a simple correspondence can be given between frame conditions and Lemmon–Scott axioms. A dynamic intuitionistic affine logic (DIAL) is proposed as an affine version of (test-free) dynamic logic, and the completeness theorem for this logic is shown with respect to Kripke semantics. Finally, some intuitive interpretations, such as resource and informational interpretations, are given for the proposed logics and semantics. By using these logics, semantics and interpretations, various kinds of fine-grained resource-sensitive reasoning can be expressed.},
	language = {en},
	number = {1},
	urldate = {2021-06-19},
	journal = {Theoretical Computer Science},
	author = {Kamide, Norihiro},
	month = mar,
	year = {2006},
	keywords = {Affine logic, Completeness, Kripke-style semantics, Linear logic, Modal logic},
	pages = {165--207},
	file = {Kamide - 2006 - Linear and affine logics with temporal, spatial an.pdf:/Users/wanchengsyuan/Zotero/storage/4KQZPBPN/Kamide - 2006 - Linear and affine logics with temporal, spatial an.pdf:application/pdf;ScienceDirect Snapshot:/Users/wanchengsyuan/Zotero/storage/WHSZ4C8Z/S0304397505007863.html:text/html},
}

@incollection{schellinx_linear_1996,
	address = {Dordrecht},
	series = {Applied {Logic} {Series}},
	title = {A {Linear} {Approach} to {Modal} {Proof} {Theory}},
	isbn = {978-94-017-2798-3},
	url = {https://doi.org/10.1007/978-94-017-2798-3_3},
	abstract = {Linear logic1 bans the structural rules of weakening and contraction from the formulation of classical logic as a sequent calculus, and re-introduces them in modalized form: structural manipulation to the left of the entailment-sign is allowed only for formulas prefixed by “!”, to the right only for those prefixed by “?”. (‘Linear’ logicians refer to !, ? as the exponentials.) The resulting calculus is a proof theoretical jewel, which combines the deep symmetries of classical, with the computational properties (strong normalization, confluence) of intuitionistic logic, without loss of expressive power.},
	language = {en},
	urldate = {2021-06-20},
	booktitle = {Proof {Theory} of {Modal} {Logic}},
	publisher = {Springer Netherlands},
	author = {Schellinx, Harold},
	editor = {Wansing, Heinrich},
	year = {1996},
	doi = {10.1007/978-94-017-2798-3_3},
	keywords = {Modal Logic, Classical Logic, Intuitionistic Logic, Linear Logic, Linear Approach},
	pages = {33--43},
}

@article{rosiger_coalgebras_2000,
	series = {{CMCS}'2000, {Coalgebraic} {Methods} in {Computer} {Science}},
	title = {Coalgebras and {Modal} {Logic}},
	volume = {33},
	issn = {1571-0661},
	url = {https://www.sciencedirect.com/science/article/pii/S1571066105803536},
	doi = {10.1016/S1571-0661(05)80353-6},
	abstract = {Coalgebras are of growing importance in theoretical computer science. To develop languages for them is significant for the specification and verification of systems. Modal logic has proved to be suitable for this purpose. So far, most approaches have presented a language to describe only deterministic coalgebras. The present paper introduces a generalization that also covers non-deterministic systems. Models for our modal language are F-coalgebras where the functor F is inductively constructed from constant sets and the identity functor using product, coproduct, exponentiation, and the power set functor. Thus, Kripke-structures constitute a special case. First we introduce a language that is based on a multisorted modal setting: here the sorts are given by the subfunctors of F. Then we consider a restricted language that still has the same expressiveness. It turns out that, for the case of Kripke-structures, the obtained language is equivalent to the “usual” modal logic for these structures. Hence this approach actually constitutes a bridge between modal languages for coalgebras and the modal logic for Kripke-structures. A well-known result from modal logic can be transfered to our setting: for so-called image-finite coalgebras bisimilarity coincides with logical equivalence. Finally, we present a sound and complete deduction calculus in case the constants in F are finite.},
	language = {en},
	urldate = {2021-06-20},
	journal = {Electronic Notes in Theoretical Computer Science},
	author = {Rößiger, Martin},
	month = jan,
	year = {2000},
	pages = {294--315},
	file = {Rößiger - 2000 - Coalgebras and Modal Logic.pdf:/Users/wanchengsyuan/Zotero/storage/LGDKSZBI/Rößiger - 2000 - Coalgebras and Modal Logic.pdf:application/pdf;ScienceDirect Snapshot:/Users/wanchengsyuan/Zotero/storage/SL6Q2A56/S1571066105803536.html:text/html},
}

@article{kupke_coalgebraic_2011,
	series = {{CMCS} {Tenth} {Anniversary} {Meeting}},
	title = {Coalgebraic semantics of modal logics: {An} overview},
	volume = {412},
	issn = {0304-3975},
	shorttitle = {Coalgebraic semantics of modal logics},
	url = {https://www.sciencedirect.com/science/article/pii/S0304397511003215},
	doi = {10.1016/j.tcs.2011.04.023},
	abstract = {Coalgebras can be seen as a natural abstraction of Kripke frames. In the same sense, coalgebraic logics are generalised modal logics. In this paper, we give an overview of the basic tools, techniques and results that connect coalgebras and modal logic. We argue that coalgebras unify the semantics of a large range of different modal logics (such as probabilistic, graded, relational, conditional) and discuss unifying approaches to reasoning at this level of generality. We review languages defined in terms of the so-called cover modality, languages induced by predicate liftings as well as their common categorical abstraction, and present (abstract) results on completeness, expressiveness and complexity in these settings, both for basic languages as well as a number of extensions, such as hybrid languages and fixpoints.},
	language = {en},
	number = {38},
	urldate = {2021-06-20},
	journal = {Theoretical Computer Science},
	author = {Kupke, Clemens and Pattinson, Dirk},
	month = sep,
	year = {2011},
	keywords = {Modal logic, Coalgebra},
	pages = {5070--5094},
	file = {Kupke and Pattinson - 2011 - Coalgebraic semantics of modal logics An overview.pdf:/Users/wanchengsyuan/Zotero/storage/KBSMY9A9/Kupke and Pattinson - 2011 - Coalgebraic semantics of modal logics An overview.pdf:application/pdf;ScienceDirect Snapshot:/Users/wanchengsyuan/Zotero/storage/ZE9R82IT/S0304397511003215.html:text/html},
}

@incollection{de_paiva_categorical_2014,
	address = {Dordrecht},
	series = {Trends in {Logic}},
	title = {Categorical {Semantics} of {Linear} {Logic} for {All}},
	isbn = {978-94-007-7548-0},
	url = {https://doi.org/10.1007/978-94-007-7548-0_9},
	abstract = {This note compares several notions of categorical model of intuitionistic linear logic in the literature. The emphasis is on explaining why choices can be made and what they amount to. My conclusion is that despite being an older and more complicated notion, linear categories are still the best way to describe models of linear logic, if one wants the correspondence between syntax and semantics to be as tight as possible.},
	language = {en},
	urldate = {2021-06-21},
	booktitle = {Advances in {Natural} {Deduction}: {A} {Celebration} of {Dag} {Prawitz}'s {Work}},
	publisher = {Springer Netherlands},
	author = {de Paiva, Valeria},
	editor = {Pereira, Luiz Carlos and Haeusler, Edward Hermann and de Paiva, Valeria},
	year = {2014},
	doi = {10.1007/978-94-007-7548-0_9},
	keywords = {Intuitionistic Logic, Linear Logic, Sequent Calculus, Linear Category, Natural Deduction},
	pages = {181--192},
	file = {Submitted Version:/Users/wanchengsyuan/Zotero/storage/865FL8Y9/de Paiva - 2014 - Categorical Semantics of Linear Logic for All.pdf:application/pdf},
}

@article{hasegawa_linear_2017,
	title = {Linear {Exponential} {Comonads} without {Symmetry}},
	volume = {238},
	issn = {2075-2180},
	url = {https://dx.doi.org/10.4204/eptcs.238.6},
	doi = {10.4204/eptcs.238.6},
	journal = {Electronic Proceedings in Theoretical Computer Science},
	author = {Hasegawa, Masahito},
	year = {2017},
	note = {Publisher: Open Publishing Association},
	pages = {54--63},
}

@inproceedings{benton_mixed_1995,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A mixed linear and non-linear logic: {Proofs}, terms and models},
	isbn = {978-3-540-49404-1},
	shorttitle = {A mixed linear and non-linear logic},
	doi = {10.1007/BFb0022251},
	abstract = {Intuitionistic linear logic regains the expressive power of intuitionistic logic through the ! (‘of course’) modality. Benton, Bierman, Hyland and de Paiva have given a term assignment system for ILL and an associated notion of categorical model in which the ! modality is modelled by a comonad satisfying certain extra conditions. Ordinary intuitionistic logic is then modelled in a cartesian closed category which arises as a full subcategory of the category of coalgebras for the comonad.This paper attempts to explain the connection between ILL and IL more directly and symmetrically by giving a logic, term calculus and categorical model for a system in which the linear and non-linear worlds exist on an equal footing, with operations allowing one to pass in both directions. We start from the categorical model of ILL given by Benton, Bierman, Hyland and de Paiva and show that this is equivalent to having a symmetric monoidal adjunction between a symmetric monoidal closed category and a cartesian closed category. We then derive both a sequent calculus and a natural deduction presentation of the logic corresponding to the new notion of model.},
	language = {en},
	booktitle = {Computer {Science} {Logic}},
	publisher = {Springer},
	author = {Benton, P. N.},
	editor = {Pacholski, Leszek and Tiuryn, Jerzy},
	year = {1995},
	keywords = {Monoidal Category, Linear Logic, Sequent Calculus, Natural Deduction, Full Subcategory},
	pages = {121--135},
}

@misc{noauthor_j_nodate,
	title = {J. {Jiang} - {On} the {Lambek} {Calculus} with an {Exchange} {Modality}},
	url = {https://click.endnote.com/viewer?doi=10.4204%2Feptcs.292.4&token=WzIwOTc1NzQsIjEwLjQyMDQvZXB0Y3MuMjkyLjQiXQ.nr2ZTXcPzdDyzTX2aXWY0mqhUnk},
	urldate = {2021-07-10},
	file = {J. Jiang - On the Lambek Calculus with an Exchange Modality:/Users/wanchengsyuan/Zotero/storage/AXTIQ8RL/viewer.html:text/html},
}

@article{jiang_lambek_2019,
	title = {On the {Lambek} {Calculus} with an {Exchange} {Modality}},
	volume = {292},
	issn = {2075-2180},
	url = {http://arxiv.org/abs/1904.06847},
	doi = {10.4204/EPTCS.292.4},
	abstract = {In this paper we introduce Commutative/Non-Commutative Logic (CNC logic) and two categorical models for CNC logic. This work abstracts Benton's Linear/Non-Linear Logic by removing the existence of the exchange structural rule. One should view this logic as composed of two logics; one sitting to the left of the other. On the left, there is intuitionistic linear logic, and on the right is a mixed commutative/non-commutative formalization of the Lambek calculus. Then both of these logics are connected via a pair of monoidal adjoint functors. An exchange modality is then derivable within the logic using the adjunction between both sides. Thus, the adjoint functors allow one to pull the exchange structural rule from the left side to the right side. We then give a categorical model in terms of a monoidal adjunction, and then a concrete model in terms of dialectica Lambek spaces.},
	urldate = {2021-07-10},
	journal = {Electronic Proceedings in Theoretical Computer Science},
	author = {Jiang, Jiaming and Eades III, Harley and de Paiva, Valeria},
	month = apr,
	year = {2019},
	note = {arXiv: 1904.06847
version: 1},
	keywords = {Computer Science - Logic in Computer Science, Computer Science - Programming Languages, F.4.1, F.3.2},
	pages = {43--89},
	annote = {Comment: In Proceedings Linearity-TLLA 2018, arXiv:1904.06159},
	file = {Jiang et al. - 2019 - On the Lambek Calculus with an Exchange Modality.pdf:/Users/wanchengsyuan/Zotero/storage/LZ6C6DFT/Jiang et al. - 2019 - On the Lambek Calculus with an Exchange Modality.pdf:application/pdf;arXiv.org Snapshot:/Users/wanchengsyuan/Zotero/storage/MXKZHCQ8/1904.html:text/html},
}

@inproceedings{benton_mixed_1994,
	title = {A {Mixed} {Linear} and {Non}-{Linear} {Logic}: {Proofs}, {Terms} and {Models}},
	shorttitle = {A {Mixed} {Linear} and {Non}-{Linear} {Logic}},
	abstract = {Intuitionistic linear logic regains the expressive power of intuitionistic logic through the ! (`of course') modality. Benton, Bierman, Hyland and de Paiva have given a term assignment system for ILL and an associated notion of categorical model in which the ! modality is modelled by a comonad satisfying certain extra conditions. Ordinary intuitionistic logic is then modelled in a cartesian closed category which arises as a full subcategory of the category of coalgebras for the comonad. This paper attempts to explain the connection between ILL and IL more directly and symmetrically by giving a logic, term calculus and categorical model for a system in which the linear and non-linear worlds exist on an equal footing, with operations allowing one to pass in both directions. We start from the categorical model of ILL given by Benton, Bierman, Hyland and de Paiva and show that this is equivalent to having a symmetric monoidal adjunction between a symmetric monoidal closed category and a ca...},
	publisher = {Springer-Verlag},
	author = {Benton, P. N.},
	year = {1994},
	pages = {121--135},
	file = {Citeseer - Snapshot:/Users/wanchengsyuan/Zotero/storage/NWB5A4UL/download.html:text/html;Benton - 1994 - A Mixed Linear and Non-Linear Logic Proofs, Terms.pdf:/Users/wanchengsyuan/Zotero/storage/L55QTN4G/Benton - 1994 - A Mixed Linear and Non-Linear Logic Proofs, Terms.pdf:application/pdf},
}

@techreport{bierman_intuitionistic_1994,
	title = {On intuitionistic linear logic},
	url = {https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-346.html},
	language = {en},
	number = {UCAM-CL-TR-346},
	urldate = {2021-07-25},
	institution = {University of Cambridge, Computer Laboratory},
	author = {Bierman, G. M.},
	year = {1994},
	file = {Snapshot:/Users/wanchengsyuan/Zotero/storage/IY54IDXU/UCAM-CL-TR-346.html:text/html},
}

@article{brown_relations_1995,
	title = {Relations and non-commutative linear logic},
	volume = {105},
	issn = {0022-4049},
	url = {https://www.sciencedirect.com/science/article/pii/0022404994001472},
	doi = {10.1016/0022-4049(94)00147-2},
	abstract = {We present a sequent calculus for non-commutative intuitionistic linear logic. We prove cut elimination for this calculus and introduce rules for the modality ! (of course). We use a representation theorem for quantales to show that our calculus with ! is sound and complete with respect to a natural class of models, relational quantales. A relational quantale is a quantale whose elements are relations on a set A, ordered by inclusion and forming a monoid under relational composition. Such quantales have been studied in several areas of theoretical computer science, and so an understanding of the logic associated with them has considerable practical application.},
	language = {en},
	number = {2},
	urldate = {2021-07-26},
	journal = {Journal of Pure and Applied Algebra},
	author = {Brown, Carolyn and Gurr, Doug},
	month = dec,
	year = {1995},
	pages = {117--136},
	file = {Brown and Gurr - 1995 - Relations and non-commutative linear logic.pdf:/Users/wanchengsyuan/Zotero/storage/MCRX98VD/Brown and Gurr - 1995 - Relations and non-commutative linear logic.pdf:application/pdf;ScienceDirect Snapshot:/Users/wanchengsyuan/Zotero/storage/IEY3WTBG/0022404994001472.html:text/html},
}

@article{kanovich_subexponentials_2019,
	title = {Subexponentials in non-commutative linear logic},
	volume = {29},
	issn = {0960-1295, 1469-8072},
	url = {https://www.cambridge.org/core/journals/mathematical-structures-in-computer-science/article/abs/subexponentials-in-noncommutative-linear-logic/198AED235060784373045941E5A70241},
	doi = {10.1017/S0960129518000117},
	abstract = {Linear logical frameworks with subexponentials have been used for the specification of, among other systems, proof systems, concurrent programming languages and linear authorisation logics. In these frameworks, subexponentials can be configured to allow or not for the application of the contraction and weakening rules while the exchange rule can always be applied. This means that formulae in such frameworks can only be organised as sets and multisets of formulae not being possible to organise formulae as lists of formulae. This paper investigates the proof theory of linear logic proof systems in the non-commutative variant. These systems can disallow the application of exchange rule on some subexponentials. We investigate conditions for when cut elimination is admissible in the presence of non-commutative subexponentials, investigating the interaction of the exchange rule with the local and non-local contraction rules. We also obtain some new undecidability and decidability results on non-commutative linear logic with subexponentials.},
	language = {en},
	number = {8},
	urldate = {2021-07-26},
	journal = {Mathematical Structures in Computer Science},
	author = {Kanovich, Max and Kuznetsov, Stepan and Nigam, Vivek and Scedrov, Andre},
	month = sep,
	year = {2019},
	note = {Publisher: Cambridge University Press},
	pages = {1217--1249},
	file = {Kanovich et al. - 2019 - Subexponentials in non-commutative linear logic.pdf:/Users/wanchengsyuan/Zotero/storage/CBYGXJW9/Kanovich et al. - 2019 - Subexponentials in non-commutative linear logic.pdf:application/pdf;Snapshot:/Users/wanchengsyuan/Zotero/storage/5UM8RZLT/198AED235060784373045941E5A70241.html:text/html},
}

@inproceedings{polakow_natural_1999,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Natural {Deduction} for {Intuitionistic} {Non}-commutative {Linear} {Logic}},
	isbn = {978-3-540-48959-7},
	doi = {10.1007/3-540-48959-2_21},
	abstract = {We present a system of natural deduction and associated term calculus for intuitionistic non-commutative linear logic (INCLL) as a conservative extension of intuitionistic linear logic. We prove subject reduction and the existence of canonical forms in the implicational fragment.},
	language = {en},
	booktitle = {Typed {Lambda} {Calculi} and {Applications}},
	publisher = {Springer},
	author = {Polakow, Jeff and Pfenning, Frank},
	editor = {Girard, Jean-Yves},
	year = {1999},
	keywords = {Linear Logic, Canonical Form, Logic Programming, Logical Relation, Reduction Rule},
	pages = {295--309},
	file = {Polakow and Pfenning - 1999 - Natural Deduction for Intuitionistic Non-commutati.pdf:/Users/wanchengsyuan/Zotero/storage/GFH46KUS/Polakow and Pfenning - 1999 - Natural Deduction for Intuitionistic Non-commutati.pdf:application/pdf},
}

@article{yetter_quantales_1990,
	title = {Quantales and (noncommutative) linear logic},
	volume = {55},
	issn = {0022-4812, 1943-5886},
	url = {https://www.cambridge.org/core/journals/journal-of-symbolic-logic/article/abs/quantales-and-noncommutative-linear-logic/1808CA04372612BCB38E8D3A8B4CCCDB},
	doi = {10.2307/2274953},
	abstract = {It is the purpose of this paper to make explicit the connection between J.-Y. Girard's “linear logic” [4], and certain models for the logic of quantum mechanics, namely Mulvey's “quantales” [9]. This will be done not only in the case of commutative linear logic, but also in the case of a version of noncommutative linear logic suggested, but not fully formalized, by Girard in lectures given at McGill University in the fall of 1987 [5], and which for reasons which will become clear later we call “cyclic linear logic”.For many of our results on quantales, we rely on the work of Niefield and Rosenthal [10].The reader should note that by “the logic of quantum mechanics” we do not mean the lattice theoretic “quantum logics” of Birkhoff and von Neumann [1], but rather a logic involving an associative (in general noncommutative) operation “and then”. Logical validity is intended to embody empirical verification (whether a physical experiment, or running a program), and the validity of A \& B (in Mulvey's notation) is to be regarded as “we have verified A, and then we have verified B”. (See M. D. Srinivas [11] for another exposition of this idea.)This of course is precisely the view of the “multiplicative conjunction”, ⊗, in the phase semantics for Girard's linear logic [4], [5]. Indeed the quantale semantics for linear logic may be regarded as an element-free version of the phase semantics.},
	language = {en},
	number = {1},
	urldate = {2021-07-26},
	journal = {The Journal of Symbolic Logic},
	author = {Yetter, David N.},
	month = mar,
	year = {1990},
	note = {Publisher: Cambridge University Press},
	pages = {41--64},
	file = {Snapshot:/Users/wanchengsyuan/Zotero/storage/99Q3XL9X/1808CA04372612BCB38E8D3A8B4CCCDB.html:text/html},
}

@article{andreoli_logic_1992,
	title = {Logic {Programming} with {Focusing} {Proofs} in {Linear} {Logic}},
	volume = {2},
	issn = {0955-792X},
	url = {https://doi.org/10.1093/logcom/2.3.297},
	doi = {10.1093/logcom/2.3.297},
	abstract = {The deep symmetry of linear logic [18] makes it suitable for providing abstract models of computation, free from implementation details which are, by nature, oriented and non-symmetrical. I propose here one such model, in the area of logic programming, where the basic computational priciple isComputation = Proof searchProofs cinsidered here are those of the Gentzen style sequent calculus for linear logic. However, proofs in this system may be redundant, in that two proofs canbe syntactically different although identical up to some irrelevant reordering or simplification of the applications of the inferences rules. This leads to an untractable proof search where the search procedure is forced to make costly choices whch turn out to be irrelevant. To overcome this problem, a subclass of proofs, called the ‘focusing’ proofs, which is both complete (any derivable formla in linear logic has a focusing proof) and tractable (many irrelevant choices in the search are eliminated when aimed at focusing proofs) is identified. The main constraint underlying the specificatuon of focusing proofs has been to preserve the symmetry of linear logic, which is its most salient feature. In particular, dual connectives have dual properties with respect to focusing proofsThen, a progrmming language, called LinLog, consisting of a fragment of linear logic, in which focussing proofs have a more compact form, is presented. Linlog deals with formulae which have a syntax similar to the of the definite clauses and goals of Horn logic, but the crucial difference here is that it allows clauses with multiple atoms in the head, connected by the ‘par’ (multiplicative disjuction). It is then shown that the syntyactic restriction induced by LinLog is not performed at the cost of any expressive power: a mapping from full linear logic to LinLog, preserving focusing proofs, and analogous to the normalization to clausal form for classical logic, is presented.},
	number = {3},
	urldate = {2021-08-23},
	journal = {Journal of Logic and Computation},
	author = {Andreoli, Jean-Mark},
	month = jun,
	year = {1992},
	pages = {297--347},
	file = {Snapshot:/Users/wanchengsyuan/Zotero/storage/LGTCIBYK/1012743.html:text/html;ANDREOLI - 1992 - Logic Programming with Focusing Proofs in Linear L.pdf:/Users/wanchengsyuan/Zotero/storage/KY9UC2C7/ANDREOLI - 1992 - Logic Programming with Focusing Proofs in Linear L.pdf:application/pdf},
}

@article{shulman_lnl_2021,
	title = {{LNL} polycategories and doctrines of linear logic},
	url = {http://arxiv.org/abs/2106.15042},
	abstract = {We define and study LNL polycategories, which abstract the judgmental structure of classical linear logic with exponentials. Many existing structures can be represented as LNL polycategories, including LNL adjunctions, linear exponential comonads, LNL multicategories, IL-indexed categories, linearly distributive categories with storage, commutative and strong monads, CBPV-structures, models of polarized calculi, skew multicategories, as well as ordinary cartesian and symmetric multicategories and monoidal categories, polycategories, and linearly distributive and *-autonomous categories. To study such classes of structures uniformly, we define a notion of LNL doctrine, such that each of these classes of structures can be identified with the algebras for some such doctrine. We show that free algebras for LNL doctrines can be presented by a sequent calculus, and that every morphism of doctrines induces an adjunction between their 2-categories of algebras.},
	urldate = {2021-08-31},
	journal = {arXiv:2106.15042 [cs, math]},
	author = {Shulman, Michael},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.15042},
	keywords = {Computer Science - Logic in Computer Science, Mathematics - Category Theory},
	annote = {Comment: 47 pages},
	file = {Shulman - 2021 - LNL polycategories and doctrines of linear logic.pdf:/Users/wanchengsyuan/Zotero/storage/IELLC6U5/Shulman - 2021 - LNL polycategories and doctrines of linear logic.pdf:application/pdf;arXiv.org Snapshot:/Users/wanchengsyuan/Zotero/storage/SRWKANMW/2106.html:text/html},
}

@article{bourke_skew_2017,
	title = {Skew structures in 2-category theory and homotopy theory},
	volume = {12},
	issn = {1512-2891},
	url = {https://doi.org/10.1007/s40062-015-0121-z},
	doi = {10.1007/s40062-015-0121-z},
	abstract = {We study Quillen model categories equipped with a monoidal skew closed structure that descends to a genuine monoidal closed structure on the homotopy category. Our examples are 2-categorical and include permutative categories and bicategories. Using the skew framework, we adapt Eilenberg and Kelly’s theorem relating monoidal and closed structure to the homotopical setting. This is applied to the construction of monoidal bicategories arising from the pseudo-commutative 2-monads of Hyland and Power.},
	language = {en},
	number = {1},
	urldate = {2021-09-28},
	journal = {Journal of Homotopy and Related Structures},
	author = {Bourke, John},
	month = mar,
	year = {2017},
	pages = {31--81},
	file = {Bourke - 2017 - Skew structures in 2-category theory and homotopy .pdf:/Users/wanchengsyuan/Zotero/storage/5FQBHVJ4/Bourke - 2017 - Skew structures in 2-category theory and homotopy .pdf:application/pdf},
}

@inproceedings{veltri_coherence_2021,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Coherence via {Focusing} for {Symmetric} {Skew} {Monoidal} {Categories}},
	isbn = {978-3-030-88853-4},
	doi = {10.1007/978-3-030-88853-4_12},
	abstract = {The symmetric skew monoidal categories of Bourke and Lack are a weakening of Mac Lane’s symmetric monoidal categories where: (i) the three structural laws of left and right unitality and associativity are not required to be invertible, they are merely natural transformations with a specific orientation; (ii) the structural law of symmetry is a natural isomorphism involving three objects rather than two. In this paper we study the structural proof theory of symmetric skew monoidal categories, progressing the project initiated by Uustalu et al. on deductive systems for categories with skew structure. We discuss three equivalent presentations of the free symmetric skew monoidal category on a set of generating objects: a Hilbert-style categorical calculus; a cut-free sequent calculus; a focused subsystem of derivations, corresponding to a sound and complete goal-directed proof search strategy for the cut-free sequent calculus. Focusing defines an effective normalization procedure for maps in the free symmetric skew monoidal category, as such solving the coherence problem for symmetric skew monoidal categories.},
	language = {en},
	booktitle = {Logic, {Language}, {Information}, and {Computation}},
	publisher = {Springer International Publishing},
	author = {Veltri, Niccolò},
	editor = {Silva, Alexandra and Wassermann, Renata and de Queiroz, Ruy},
	year = {2021},
	keywords = {Agda, Coherence, Focused sequent calculus, Substructural logic, Symmetric skew monoidal categories},
	pages = {184--200},
	file = {Springer Full Text PDF:/Users/wanchengsyuan/Zotero/storage/8FPFBXZ6/Veltri - 2021 - Coherence via Focusing for Symmetric Skew Monoidal.pdf:application/pdf},
}

@article{bourke_free_2018,
	title = {Free skew monoidal categories},
	volume = {222},
	issn = {0022-4049},
	url = {https://www.sciencedirect.com/science/article/pii/S002240491730289X},
	doi = {10.1016/j.jpaa.2017.12.006},
	abstract = {In the paper Triangulations, orientals, and skew monoidal categories, the free skew monoidal category Fsk on a single generating object was described. We sharpen this by giving a completely explicit description of Fsk, and so of the free skew monoidal category on any category. As an application we describe adjunctions between the operad for skew monoidal categories and various simpler operads. For a particular such operad L, we identify skew monoidal categories with certain colax L-algebras.},
	language = {en},
	number = {10},
	urldate = {2021-10-25},
	journal = {Journal of Pure and Applied Algebra},
	author = {Bourke, John and Lack, Stephen},
	month = oct,
	year = {2018},
	pages = {3255--3281},
	file = {Submitted Version:/Users/wanchengsyuan/Zotero/storage/WVKNK72I/Bourke and Lack - 2018 - Free skew monoidal categories.pdf:application/pdf},
}

@article{bourke_skew_2018-1,
	title = {Skew monoidal categories and skew multicategories},
	volume = {506},
	issn = {0021-8693},
	url = {https://www.sciencedirect.com/science/article/pii/S0021869318301996},
	doi = {10.1016/j.jalgebra.2018.02.039},
	abstract = {We describe a perfect correspondence between skew monoidal categories and certain generalised multicategories, called skew multicategories, that arise in nature.},
	language = {en},
	urldate = {2021-10-25},
	journal = {Journal of Algebra},
	author = {Bourke, John and Lack, Stephen},
	month = jul,
	year = {2018},
	keywords = {Multicategory, Operad, Skew monoidal category},
	pages = {237--266},
	file = {Submitted Version:/Users/wanchengsyuan/Zotero/storage/M5VLYTUI/Bourke and Lack - 2018 - Skew monoidal categories and skew multicategories.pdf:application/pdf},
}

@article{buckley_catalan_2015,
	title = {The {Catalan} simplicial set},
	volume = {158},
	issn = {0305-0041, 1469-8064},
	url = {https://www.cambridge.org/core/journals/mathematical-proceedings-of-the-cambridge-philosophical-society/article/catalan-simplicial-set/7340716969F921F6A98AF871525F12AB},
	doi = {10.1017/S0305004114000498},
	abstract = {The Catalan numbers are well known to be the answer to many different counting problems, and so there are many different families of sets whose cardinalities are the Catalan numbers. We show how such a family can be given the structure of a simplicial set. We show how the low-dimensional parts of this simplicial set classify, in a precise sense, the structures of monoid and of monoidal category. This involves aspects of combinatorics, algebraic topology, quantum groups, logic, and category theory.},
	language = {en},
	number = {2},
	urldate = {2021-10-25},
	journal = {Mathematical Proceedings of the Cambridge Philosophical Society},
	author = {Buckley, Mitchell and Garner, Richard and Lack, Stephen and Street, Ross},
	month = mar,
	year = {2015},
	note = {Publisher: Cambridge University Press},
	pages = {211--222},
	file = {Full Text PDF:/Users/wanchengsyuan/Zotero/storage/C5M6B5AB/Buckley et al. - 2015 - The Catalan simplicial set.pdf:application/pdf;Snapshot:/Users/wanchengsyuan/Zotero/storage/CRUM2ANY/7340716969F921F6A98AF871525F12AB.html:text/html},
}

@article{lack_skew_2012,
	title = {Skew monoidales, skew warpings and quantum categories},
	volume = {26},
	url = {http://arxiv.org/abs/1205.0074},
	abstract = {Kornel Szlach{\textbackslash}'anyi recently used the term skew-monoidal category for a particular laxified version of monoidal category. He showed that bialgebroids \$H\$ with base ring \$R\$ could be characterized in terms of skew-monoidal structures on the category of one-sided \$R\$-modules for which the lax unit was \$R\$ itself. We define skew monoidales (or skew pseudo-monoids) in any monoidal bicategory \${\textbackslash}mathscr M\$. These are skew-monoidal categories when \${\textbackslash}mathscr M\$ is \${\textbackslash}mathrm\{Cat\}\$. Our main results are presented at the level of monoidal bicategories. However, a consequence is that quantum categories in the sense of Day-Street with base comonoid \$C\$ in a suitably complete braided monoidal category \${\textbackslash}mathscr V\$ are precisely skew monoidales in \${\textbackslash}mathrm\{Comod\} ({\textbackslash}mathscr V)\$ with unit coming from the counit of \$C\$. Quantum groupoids are those skew monoidales with invertible associativity constraint. In fact, we provide some very general results connecting opmonoidal monads and skew monoidales. We use a lax version of the concept of warping defined recently by Booker-Street to modify monoidal structures.},
	urldate = {2021-10-25},
	journal = {Theory and Applications of Categories},
	author = {Lack, Stephen and Street, Ross},
	month = sep,
	year = {2012},
	note = {arXiv: 1205.0074},
	keywords = {Mathematics - Category Theory, Mathematics - Quantum Algebra},
	pages = {385--402},
	annote = {Comment: Minor changes and some renumbering in this version},
	file = {arXiv Fulltext PDF:/Users/wanchengsyuan/Zotero/storage/G8PKDGQC/Lack and Street - 2012 - Skew monoidales, skew warpings and quantum categor.pdf:application/pdf;arXiv.org Snapshot:/Users/wanchengsyuan/Zotero/storage/BW4NAH3L/1205.html:text/html},
}

@article{bourke_braided_nodate,
	title = {{BRAIDED} {SKEW} {MONOIDAL} {CATEGORIES}},
	volume = {35},
	abstract = {We introduce the notion of a braiding on a skew monoidal category, whose curious feature is that the deﬁning isomorphisms involve three objects rather than two. Examples are shown to arise from 2-category theory and from bialgebras. In order to describe the 2-categorical examples, we take a multicategorical approach. We explain how certain braided skew monoidal structures in the 2-categorical setting give rise to braided monoidal bicategories. For the bialgebraic examples, we show that, for a skew monoidal category arising from a bialgebra, braidings on the skew monoidal category are in bijection with cobraidings (also known as coquasitriangular structures) on the bialgebra.},
	language = {en},
	journal = {Theory and Applications of CategoriesB C},
	author = {Bourke, John and Lack, Stephen},
	pages = {19--63},
	file = {Bourke and Lack - BRAIDED SKEW MONOIDAL CATEGORIES.pdf:/Users/wanchengsyuan/Zotero/storage/ZHXPYSTY/Bourke and Lack - BRAIDED SKEW MONOIDAL CATEGORIES.pdf:application/pdf},
}
